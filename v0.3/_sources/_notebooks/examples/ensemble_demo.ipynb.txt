{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uncertainty Quantification Ensemble Demo (Advanced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Content\n",
    "1. [Introduction](#section1')\n",
    "2. [Set up LLM and Prompts](#section2')\n",
    "3. [Generate Responses and Confidence Scores](#section3')<br>\n",
    "4. [Tune Parameters](#section4')\n",
    "5. [Performance Evaluation](#section5')\n",
    "6. [Scorer Definitions](#section6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.cache/pypoetry/virtualenvs/uqlm-g7jzkC-R-py3.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-03-05 18:15:53.296157: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1741198553.320653   20612 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1741198553.328239   20612 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-05 18:15:53.353527: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "from uqlm.utils import load_example_dataset, math_postprocessor, plot_model_accuracies\n",
    "from uqlm.quantifiers import UQEnsemble\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section1'></a>\n",
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Ensemble UQ methods combine multiple individual scorers to provide a more robust and accurate uncertainty estimate. They offer high flexibility and customizability, allowing you to tailor the ensemble to specific use cases.\n",
    "\n",
    "**Pros:**\n",
    "\n",
    "*   ✅  **Highly Flexible:** Versatile and adaptable to various tasks and question types.\n",
    "*   ✅  **Highly Customizable:** Ensemble weights can be tuned for optimal performance on a specific use case.\n",
    "\n",
    "**Cons:**\n",
    "\n",
    "*   ⚠️  **Requires More Setup:** Not quite \"off-the-shelf\"; requires some effort to configure and tune the ensemble.\n",
    "*   ⚠️  **Best for Advanced Users:**  Optimizing the ensemble requires a deeper understanding of the individual scorers.\n",
    "\n",
    "**Available Scorers:**\n",
    "\n",
    "*   BS Detector ([Chen & Mueller, 2023](https://arxiv.org/abs/2308.16175))\n",
    "*   Generalized Ensemble (uses any combination of black-box, white-box, and LLM-as-a-judge scorers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section2'></a>\n",
    "## 2. Set up LLM and Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset - svamp...\n",
      "Processing dataset...\n",
      "Dataset ready!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>There are 87 oranges and 290 bananas in Philip...</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Marco and his dad went strawberry picking. Mar...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Edward spent $ 6 to buy 2 books each book cost...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Frank was reading through his favorite book. T...</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>There were 78 dollars in Olivia's wallet. She ...</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question answer\n",
       "0  There are 87 oranges and 290 bananas in Philip...    145\n",
       "1  Marco and his dad went strawberry picking. Mar...     19\n",
       "2  Edward spent $ 6 to buy 2 books each book cost...      3\n",
       "3  Frank was reading through his favorite book. T...    198\n",
       "4  There were 78 dollars in Olivia's wallet. She ...     63"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loaod example dataset (SVAMP)\n",
    "svamp = (\n",
    "    load_example_dataset(\"svamp\")\n",
    "    .rename(columns={\"question_concat\": \"question\", \"Answer\": \"answer\"})[\n",
    "        [\"question\", \"answer\"]\n",
    "    ]\n",
    "    .head(100)\n",
    ")\n",
    "svamp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "svamp_tune = svamp.iloc[0:50]\n",
    "svamp_test = svamp.iloc[51:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define prompts\n",
    "MATH_INSTRUCTION = (\n",
    "    \"When you solve this math problem only return the answer with no additional text.\\n\"\n",
    ")\n",
    "tune_prompts = [MATH_INSTRUCTION + prompt for prompt in svamp_tune.question]\n",
    "test_prompts = [MATH_INSTRUCTION + prompt for prompt in svamp_test.question]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# User to populate .env file with API credentials\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "gpt = AzureChatOpenAI(\n",
    "    deployment_name=os.getenv(\"DEPLOYMENT_NAME\"),\n",
    "    openai_api_key=os.getenv(\"API_KEY\"),\n",
    "    azure_endpoint=os.getenv(\"API_BASE\"),\n",
    "    openai_api_type=os.getenv(\"API_TYPE\"),\n",
    "    openai_api_version=os.getenv(\"API_VERSION\"),\n",
    "    temperature=1,  # User to set temperature\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Instantiate Gemini models\n",
    "from langchain_google_vertexai import ChatVertexAI\n",
    "\n",
    "gemini_pro = ChatVertexAI(model_name=\"gemini-pro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that although we use `ChatVertexAI` and `AzureChatOpenAI` in this example, any [LangChain Chat Model](https://js.langchain.com/docs/integrations/chat/) may be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section3'></a>\n",
    "## 3. Generate responses and confidence scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### `UQEnsemble()` - Ensemble of uncertainty quantifiers (class).\n",
    "\n",
    "**Class Attributes:**\n",
    "- `llm` (**BaseChatModel, default=None**) A langchain llm (`BaseChatModel`). User is responsible for specifying temperature and other relevant parameters to the constructor of their `BaseChatModel` object.\n",
    "- `components` - (**List containing instances of BaseChatModel, LLMJudge, or elements of [\"semantic_entropy\", \"mean_nli\",\n",
    "        \"exact_match\", \"self_reflection\", \"bert_score\", \"bleurt_score\", \"cosine_similarity\"], default=None**) Specifies which UQ components to include. If None, defaults to [\"semantic_entropy\", \"mean_nli\", \"exact_match\",\"self_reflection\"]=\n",
    "- `device` - (**str or torch.device input or torch.device object, default=\"cpu\"**) Specifies the device that classifiers use for prediction. Set to \"cuda\" for classifiers to be able to leverage the GPU.\n",
    "- `system_prompt` - (**str or None, default=\"You are a helpful assistant.\"**) Optional argument for user to provide custom system prompt\n",
    "- `max_calls_per_min` - (**int, default=None**) Specifies how many api calls to make per minute to avoid a rate limit error. By default, no limit is specified.\n",
    "- `use_n_param` (**bool, default=False**) Specifies whether to use `n` parameter for `BaseChatModel`. Not compatible with all `BaseChatModel` classes. If used, it speeds up the generation process substantially when `num_responses` is large.\n",
    "- `postprocessor` - (**(str) -> str, default=None**) A class object to compute the self-reflection certainty score. If not provided, this method will use defined 'langchain_llm' with 0 temperature.\n",
    "- `self_reflection_generator` - (**ResponseGenerator, default=None**) A class object to compute the self-reflection certainty score. If not provided, this method will use defined 'langchain_llm' with 0 temperature.\n",
    "- `weights` - (**list of floats, default= None**) Specifies weight for each component in ensemble. If none, each component receives equal weight.\n",
    "- `nli_model_name` (**str, default=\"microsoft/deberta-large-mnli\"**) Specifies which NLI model to use. Must be acceptable input to `AutoTokenizer.from_pretrained()` and `AutoModelForSequenceClassification.from_pretrained()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\")  # use if GPU available\n",
    "# device = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-large-mnli were not used when initializing DebertaForSequenceClassification: ['config']\n",
      "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "components = [\n",
    "    \"match_score\",  # Measures proportion of candidate responses that match original response (black-box)\n",
    "    \"noncontradiction_score\",  # mean non-contradiction probability between candidate responses and original response (black-box)\n",
    "    \"normalized_probability\",  # length-normalized joint token probability (white-box)\n",
    "    gemini_pro,  # LLM-as-a-judge (self)\n",
    "    gpt,  # LLM-as-a-judge (separate LLM)\n",
    "]\n",
    "\n",
    "uqe = UQEnsemble(\n",
    "    llm=gemini_pro,\n",
    "    device=device,\n",
    "    max_calls_per_min=250,\n",
    "    # postprocessor=math_postprocessor,\n",
    "    use_n_param=False,  # Set True if using AzureChatOpenAI for faster generation\n",
    "    components=components,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`UQEnsemble.evaluate` - Generate responses and evaluate confidence scores on LLM responses for the provided prompts..\n",
    "\n",
    "**Method Arguments:**\n",
    "- `prompts` - (**list of str**) A list of input prompts for the model.\n",
    "- `responses` - (**list of str, default=None**) A list of model responses for the prompts. If not provided, this method will generate responses for `self.llm`. \n",
    "- `multiple_responses` - (**list of list of str, default=None**) A list of multiple model responses, each element (multiple_responses[i]) is a list of str, containing multiple model responses for prompts[i]. If not provided, this method will generate responses for `self.llm`.\n",
    "- `mr_temperature` - (**float, default=1**) The `temperature` parameter for llm model to generate multiple responses\n",
    "- `num_responses` - (**int, default=5**) The number of multiple responses used to compute observed consistency.\n",
    "\n",
    "**Returns:**\n",
    "    `UQResult` containing data (prompts, responses, and confidence scores) and metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses...\n",
      "Generating candidate responses...\n",
      "Computing confidence scores...\n",
      "Generating LLMJudge scores...\n",
      "Generating LLMJudge scores...\n",
      "Computing confidence scores...\n"
     ]
    }
   ],
   "source": [
    "results = await uqe.evaluate(prompts=tune_prompts, num_responses=5, use_best=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>response</th>\n",
       "      <th>multiple_responses</th>\n",
       "      <th>confidence_score</th>\n",
       "      <th>match_score</th>\n",
       "      <th>noncontradiction_score</th>\n",
       "      <th>normalized_probability</th>\n",
       "      <th>judge_1</th>\n",
       "      <th>judge_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>When you solve this math problem only return t...</td>\n",
       "      <td>145</td>\n",
       "      <td>[145, 145, 145, 145, 145]</td>\n",
       "      <td>0.698637</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.993186</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When you solve this math problem only return t...</td>\n",
       "      <td>19 pounds</td>\n",
       "      <td>[$19$, 19 pounds., 19, 19 pounds, 19]</td>\n",
       "      <td>0.445825</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.818286</td>\n",
       "      <td>0.210841</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>When you solve this math problem only return t...</td>\n",
       "      <td>$ 3.00</td>\n",
       "      <td>[$3.00, 4, 3, $ 3.00, $3 \\n]</td>\n",
       "      <td>0.581271</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.862477</td>\n",
       "      <td>0.843878</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>When you solve this math problem only return t...</td>\n",
       "      <td>198</td>\n",
       "      <td>[198, 198, 198, 198, 198]</td>\n",
       "      <td>0.798186</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990932</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>When you solve this math problem only return t...</td>\n",
       "      <td>63</td>\n",
       "      <td>[$63, 63 dollars, 63, 63 dollars., 63]</td>\n",
       "      <td>0.570754</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.964027</td>\n",
       "      <td>0.489743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt   response  \\\n",
       "0  When you solve this math problem only return t...        145   \n",
       "1  When you solve this math problem only return t...  19 pounds   \n",
       "2  When you solve this math problem only return t...     $ 3.00   \n",
       "3  When you solve this math problem only return t...        198   \n",
       "4  When you solve this math problem only return t...         63   \n",
       "\n",
       "                       multiple_responses  confidence_score  match_score  \\\n",
       "0               [145, 145, 145, 145, 145]          0.698637          1.0   \n",
       "1   [$19$, 19 pounds., 19, 19 pounds, 19]          0.445825          0.2   \n",
       "2            [$3.00, 4, 3, $ 3.00, $3 \\n]          0.581271          0.2   \n",
       "3               [198, 198, 198, 198, 198]          0.798186          1.0   \n",
       "4  [$63, 63 dollars, 63, 63 dollars., 63]          0.570754          0.4   \n",
       "\n",
       "   noncontradiction_score  normalized_probability  judge_1  judge_2  \n",
       "0                1.000000                0.993186      0.0      0.5  \n",
       "1                0.818286                0.210841      1.0      0.0  \n",
       "2                0.862477                0.843878      0.0      1.0  \n",
       "3                1.000000                0.990932      0.0      1.0  \n",
       "4                0.964027                0.489743      0.0      1.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = results.to_df()\n",
    "result_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section4'></a>\n",
    "## 4. Tune Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tune parameters and reassess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`UQEnsemble.tune_params` - Tunes weights and threshold on a set of user-provided graded responses. \n",
    "\n",
    "**Method Arguments:**\n",
    "- `correct_indicators` - (**list of bool**) A list of boolean indicators of whether self.original_responses are correct.\n",
    "- `weight_bounds` - (**list of 2-tuples of floats, default = [(0,1), (0,1), (0,1), (0,1)]**) Bounds of parameters for weights for scipy minimize function. Order must correspond to order of self.components.\n",
    "- `weights_objective` - (**{'fbeta_score', 'accuracy_score', 'balanced_accuracy_score', 'roc_auc', 'log_loss'}, default='roc_auc'**) Objective function for optimization of alpha and beta. Must match thresh_objective if one of 'fbeta_score',          \n",
    "- `thresh_bounds` - (**tuple of floats, default=(0,1)**) Bounds to search for threshold\n",
    "- `thresh_objective` - (**{'fbeta_score', 'accuracy_score', 'balanced_accuracy_score', 'roc_auc', 'log_loss'}, default='fbeta_score'**) Objective function for threshold optimization via grid search.\n",
    "- `n_trials` - (**int, default=100**) Indicates how many candidates to search over with optuna optimizer\n",
    "- `grid_search_alpha_beta` - (**bool, default=False**) Indicates whether to conduct grid search as optimization routine for alpha and beta\n",
    "- `step_size` - (**float, default=0.01**) Indicates step size in grid search, if used\n",
    "- `fscore_beta` - (**float, default=1**) Value of beta in fbeta_score   \n",
    "\n",
    "**Returns:**\n",
    "    Instance of UQEnsembleResult, containing data (prompts, responses, and confidence scores) and metadata (parameters, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Populate correct answers and grade responses\n",
    "correct_indicators = [\n",
    "    math_postprocessor(r) == a\n",
    "    for r, a in zip(result_df[\"response\"], svamp_tune[\"answer\"])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing weights...\n",
      "Optimizing threshold with grid search...\n"
     ]
    }
   ],
   "source": [
    "tuned_result = uqe.tune_params(\n",
    "    correct_indicators=correct_indicators, weights_objective=\"roc_auc\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight for match_score: 0.31101559912033366\n",
      "Weight for noncontradiction_score: 0.28149817493332807\n",
      "Weight for normalized_probability: 0.3174254003685539\n",
      "Weight for judge_1: 0.006798364703485985\n",
      "Weight for judge_2: 0.08326246087429848\n"
     ]
    }
   ],
   "source": [
    "# View optimized_weights\n",
    "for i, weight in enumerate(uqe.weights):\n",
    "    print(f\"Weight for {uqe.component_names[i]}: {weight}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section5'></a>\n",
    "## 5. Evaluate Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate performance, we will generate responses and corresponding confidence scores on a holdout set using the tuned ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating responses...\n",
      "Generating candidate responses...\n",
      "Computing confidence scores...\n",
      "Generating LLMJudge scores...\n",
      "Generating LLMJudge scores...\n",
      "Computing confidence scores...\n"
     ]
    }
   ],
   "source": [
    "test_results = await uqe.evaluate(prompts=test_prompts, num_responses=5, use_best=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>response</th>\n",
       "      <th>multiple_responses</th>\n",
       "      <th>confidence_score</th>\n",
       "      <th>match_score</th>\n",
       "      <th>noncontradiction_score</th>\n",
       "      <th>normalized_probability</th>\n",
       "      <th>judge_1</th>\n",
       "      <th>judge_2</th>\n",
       "      <th>response_correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>When you solve this math problem only return t...</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 1, 1, 1, 1]</td>\n",
       "      <td>0.908257</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994699</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When you solve this math problem only return t...</td>\n",
       "      <td>27</td>\n",
       "      <td>[27, 27, 27, 27, 87]</td>\n",
       "      <td>0.801006</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.821439</td>\n",
       "      <td>0.989717</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>When you solve this math problem only return t...</td>\n",
       "      <td>4</td>\n",
       "      <td>[4, 4, 4, 4, 4]</td>\n",
       "      <td>0.995645</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.986279</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>When you solve this math problem only return t...</td>\n",
       "      <td>17</td>\n",
       "      <td>[27, 17, 17, 17, 17]</td>\n",
       "      <td>0.563772</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.827284</td>\n",
       "      <td>0.258584</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>When you solve this math problem only return t...</td>\n",
       "      <td>16</td>\n",
       "      <td>[16 \\n, 16, 16, 16, 22\\n]</td>\n",
       "      <td>0.730174</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.815858</td>\n",
       "      <td>0.967482</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt response  \\\n",
       "0  When you solve this math problem only return t...        1   \n",
       "1  When you solve this math problem only return t...       27   \n",
       "2  When you solve this math problem only return t...        4   \n",
       "3  When you solve this math problem only return t...       17   \n",
       "4  When you solve this math problem only return t...       16   \n",
       "\n",
       "          multiple_responses  confidence_score  match_score  \\\n",
       "0            [1, 1, 1, 1, 1]          0.908257          1.0   \n",
       "1       [27, 27, 27, 27, 87]          0.801006          0.8   \n",
       "2            [4, 4, 4, 4, 4]          0.995645          1.0   \n",
       "3       [27, 17, 17, 17, 17]          0.563772          0.8   \n",
       "4  [16 \\n, 16, 16, 16, 22\\n]          0.730174          0.6   \n",
       "\n",
       "   noncontradiction_score  normalized_probability  judge_1  judge_2  \\\n",
       "0                1.000000                0.994699      0.0      0.0   \n",
       "1                0.821439                0.989717      1.0      0.0   \n",
       "2                1.000000                0.986279      1.0      1.0   \n",
       "3                0.827284                0.258584      0.0      0.0   \n",
       "4                0.815858                0.967482      1.0      0.0   \n",
       "\n",
       "   response_correct  \n",
       "0              True  \n",
       "1              True  \n",
       "2              True  \n",
       "3              True  \n",
       "4             False  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_result_df = test_results.to_df()\n",
    "test_result_df[\"response_correct\"] = [\n",
    "    math_postprocessor(r) == a\n",
    "    for r, a in zip(test_result_df[\"response\"], svamp_test[\"answer\"])\n",
    "]\n",
    "test_result_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline LLM accuracy: 0.6530612244897959\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"Baseline LLM accuracy: {np.mean(test_result_df[\"response_correct\"])}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will plot filtered LLM accuracy at various confidence score thresholds. The idea is to measure the LLM's performance when we consider responses with confidence scores above a given threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_model_accuracies(\n",
    "    scores=test_result_df.confidence_score,\n",
    "    correct_indicators=test_result_df.response_correct,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we will compute the optimal threshold for binarizing confidence scores, using F1-score as the objective. Using this threshold, we can compute precision, recall, and F1-score for semantic entropy predictions of whether responses are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble F1-optimal threshold: 0.4\n"
     ]
    }
   ],
   "source": [
    "# extract optimal threshold\n",
    "best_threshold = uqe.thresh\n",
    "\n",
    "# Define score vector and corresponding correct indicators (i.e. ground truth)\n",
    "y_scores = test_result_df[\"confidence_score\"]  # confidence score\n",
    "correct_indicators = (\n",
    "    test_result_df.response_correct\n",
    ") * 1  # Whether responses is actually correct\n",
    "y_pred = [\n",
    "    (s > best_threshold) * 1 for s in y_scores\n",
    "]  # predicts whether response is correct based on confidence score\n",
    "print(f\"Ensemble F1-optimal threshold: {best_threshold}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble precision: 0.7317073170731707\n",
      "Ensemble recall: 0.9375\n",
      "Ensemble f1-score: 0.821917808219178\n"
     ]
    }
   ],
   "source": [
    "# evaluate precision, recall, and f1-score of semantic entropy predictions of correctness\n",
    "print(\n",
    "    f\"Ensemble precision: {precision_score(y_true=correct_indicators, y_pred=y_pred)}\"\n",
    ")\n",
    "print(f\"Ensemble recall: {recall_score(y_true=correct_indicators, y_pred=y_pred)}\")\n",
    "print(f\"Ensemble f1-score: {f1_score(y_true=correct_indicators, y_pred=y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section6'></a>\n",
    "## 6. Scorer Definitions\n",
    "\n",
    "### Black-Box Scorers\n",
    "Black-Box UQ scorers exploit variation in LLM responses to the same prompt to measure semantic consistency. All scorers have outputs ranging from 0 to 1, with higher values indicating higher confidence. \n",
    "\n",
    "For a given prompt $x_i$, these approaches involves generating $m$ responses $\\tilde{\\mathbf{y}}_i = \\{ \\tilde{y}_{i1},...,\\tilde{y}_{im}\\}$, using a non-zero temperature, from the same prompt and comparing these responses to the original response $y_{i}$. We provide detailed descriptions of each below.\n",
    "\n",
    "#### Exact Match Rate (`match_score`)\n",
    "Exact Match Rate (EMR) computes the proportion of candidate responses that are identical to the original response.\n",
    "$$     EMR(y_i; \\tilde{\\mathbf{y}}_i) = \\frac{1}{m} \\sum_{j=1}^m \\mathbb{I}(y_i=\\tilde{y}_{ij}). $$\n",
    "\n",
    "For more on this scorer, refer to [Cole et al., 2023](https://arxiv.org/abs/2305.14613).\n",
    "\n",
    "#### Non-Contradiction Probability (`noncontradiction_score`)\n",
    "Non-contradiction probability (NCP) computes the mean non-contradiction probability estimated by a natural language inference (NLI) model. This score is formally defined as follows:\n",
    "\n",
    "\\begin{equation}\n",
    "    NCP(y_i; \\tilde{\\mathbf{y}}_i) = \\frac{1}{m} \\sum_{j=1}^m(1 - p_j)\n",
    "\\end{equation}\n",
    "where\n",
    "\n",
    "\\begin{equation}\n",
    "    p_j = \\frac{\\eta(y_{i}, \\tilde{y}_{ij}) + \\eta(\\tilde{y}_{ij},y_i)}{2}.\n",
    "\\end{equation}\n",
    "\n",
    "Above, $\\eta(\\tilde{y}_{ij},y_i)$ denotes the contradiction probability estimated by the NLI model for response $y_i$ and candidate $\\tilde{y}_{ij}$. For more on this scorer, refer to [Chen & Mueller, 2023](https://arxiv.org/abs/2308.16175), [Lin et al., 2025](https://arxiv.org/abs/2305.19187), or [Manakul et al., 2023](https://arxiv.org/abs/2303.08896).\n",
    "\n",
    "#### Normalized Semantic Negentropy (`entropy_score`)\n",
    "Normalized Semantic Negentropy (NSN) normalizes the standard computation of discrete semantic entropy to be increasing with higher confidence and have [0,1] support. In contrast to the EMR and NCP, semantic entropy does not distinguish between an original response and candidate responses. Instead, this approach computes a single metric value on a list of responses generated from the same prompt. Under this approach, responses are clustered using an NLI model based on mutual entailment. We consider the discrete version of SE, where the final set of clusters is defined  as follows:\n",
    "\n",
    "\\begin{equation}\n",
    "    SE(y_i; \\tilde{\\mathbf{y}}_i) = - \\sum_{C \\in \\mathcal{C}} P(C|y_i, \\tilde{\\mathbf{y}}_i)\\log P(C|y_i, \\tilde{\\mathbf{y}}_i),\n",
    "\\end{equation}\n",
    "where $P(C|y_i, \\tilde{\\mathbf{y}}_i)$ denotes the probability a randomly selected response $y \\in \\{y_i\\} \\cup \\tilde{\\mathbf{y}}_i $ belongs to cluster $C$, and $\\mathcal{C}$ denotes the full set of clusters of $\\{y_i\\} \\cup \\tilde{\\mathbf{y}}_i$.\n",
    "\n",
    "To ensure that we have a normalized confidence score with $[0,1]$ support and with higher values corresponding to higher confidence, we implement the following normalization to arrive at \\textit{Normalized Semantic Negentropy} (NSN):\n",
    "\\begin{equation}\n",
    "    NSN(y_i; \\tilde{\\mathbf{y}}_i) = 1 - \\frac{SE(y_i; \\tilde{\\mathbf{y}}_i)}{\\log m},\n",
    "\\end{equation}\n",
    "where $\\log m$ is included to normalize the support.\n",
    "\n",
    "#### BERTScore (`bert_score`)\n",
    "Let a tokenized text sequence be denoted as $\\textbf{t} = \\{t_1,...t_L\\}$ and the corresponding contextualized word embeddings as $\\textbf{E} = \\{\\textbf{e}_1,...,\\textbf{e}_L\\}$, where $L$ is the number of tokens in the text. The BERTScore precision, recall, and F1-scores between two tokenized texts  $\\textbf{t}, \\textbf{t}'$ are respectively defined as follows:\n",
    "\n",
    "\\begin{equation}\n",
    "    BertP(\\textbf{t}, \\textbf{t}') = \\frac{1}{| \\textbf{t}|} \\sum_{t \\in \\textbf{t}} \\max_{t' \\in \\textbf{t}'} \\textbf{e} \\cdot \\textbf{e}'\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "    BertR(\\textbf{t}, \\textbf{t}') = \\frac{1}{| \\textbf{t}'|} \\sum_{t' \\in \\textbf{t}'} \\max_{t \\in \\textbf{t}} \\textbf{e} \\cdot \\textbf{e}'\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "    BertF(\\textbf{t}, \\textbf{t}') = 2\\frac{ BertP(\\textbf{t}, \\textbf{t}')  BertR(\\textbf{t}, \\textbf{t}')}{BertPr(\\textbf{t}, \\textbf{t}')  + BertRec(\\textbf{t}, \\textbf{t}')},\n",
    "\\end{equation}\n",
    "where $e, e'$ respectively correspond to $t, t'$. We compute our BERTScore-based confidence scores as follows:\n",
    "\\begin{equation}\n",
    "    BertConfidence(y_i; \\tilde{\\mathbf{y}}_i) = \\frac{1}{m} \\sum_{j=1}^m BertF(y_i, \\tilde{y}_{ij}),\n",
    "\\end{equation}\n",
    "i.e. the average BERTScore F1 across pairings of the original response with all candidate responses. For more on BERTScore, refer to [Zheng et al., 2020](https://arxiv.org/abs/1904.09675).\n",
    "\n",
    "#### BLEURT (`bleurt_score`)\n",
    "In contrast to the aforementioned scorers, BLEURT is specifically pre-trained and fine-tuned to learn human judgments of text similarity.\\footnote{We use the recommended BLEURT checkpoint of \\texttt{BLEURT-20}. Our BLEURT confidence score is the average BLEURT value across pairings of the original response with all candidate responses:\n",
    "\n",
    "\\begin{equation}\n",
    "    BLEURTConfidence(y_i; \\tilde{\\mathbf{y}}_i) = \\frac{1}{m} \\sum_{j=1}^m BLEURT(y_i, \\tilde{y}_{ij}).\n",
    "\\end{equation}\n",
    "\n",
    "For more on this scorer, refer to [Sellam et al., 2020](https://arxiv.org/abs/2004.04696).\n",
    "\n",
    "\n",
    "#### Normalized Cosine Similarity (`cosine_scorer`)\n",
    "This scorer leverages a sentence transformer to map LLM outputs to an embedding space and measure similarity using those sentence embeddings. Let $V: \\mathcal{Y} \\xrightarrow{} \\mathbb{R}^d$ denote the sentence transformer, where $d$ is the dimension of the embedding space. The average cosine similarity across pairings of the original response with all candidate responses is given as follows:\n",
    "\n",
    "\\begin{equation}\n",
    "    CS(y_i; \\tilde{\\mathbf{y}}_i) = \\frac{1}{m} \\sum_{i=1}^m   \\frac{\\mathbf{V}(y_i) \\cdot \\mathbf{V}(\\tilde{y}_{ij}) }{ \\lVert \\mathbf{V}(y_i) \\rVert \\lVert \\mathbf{V}(\\tilde{y}_{ij}) \\rVert}.\n",
    "\\end{equation}\n",
    "\n",
    "To ensure a standardized support of $[0, 1]$, we normalize cosine similarity to obtain confidence scores as follows:\n",
    "\n",
    "\\begin{equation}\n",
    "    NCS(y_i; \\tilde{\\mathbf{y}}_i) = \\frac{CS(y_i; \\tilde{\\mathbf{y}}_i) + 1}{2}.\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "### White-Box UQ Scorers\n",
    "White-box UQ scorers leverage token probabilities of the LLM's generated response to quantify uncertainty. All scorers have outputs ranging from 0 to 1, with higher values indicating higher confidence. We define two white-box UQ scorers below.\n",
    "\n",
    "#### Length-Normalized Token Probability (`normalized_probability`)\n",
    "Let the tokenization LLM response $y_i$ be denoted as $\\{t_1,...,t_{L_i}\\}$, where $L_i$ denotes the number of tokens the response. Length-normalized token probability (LNTP) computes a length-normalized analog of joint token probability:\n",
    "\n",
    "\\begin{equation}\n",
    "    LNTP(y_i) = \\prod_{t \\in y_i}  p_t^{L_i},\n",
    "\\end{equation}\n",
    "where $p_t$ denotes the token probability for token $t$. Note that this score is equivalent to the geometric mean of token probabilities for response $y_i$. For more on this scorer, refer to [Malinin & Gales, 2021](https://arxiv.org/pdf/2002.07650).\n",
    "\n",
    "\n",
    "#### Minimum Token Probability (`min_probability`)\n",
    "Minimum token probability (MTP) uses the minimum among token probabilities for a given responses as a confidence score:\n",
    "\n",
    "\\begin{equation}\n",
    "    MTP(y_i) = \\min_{t \\in y_i}  p_t,\n",
    "\\end{equation}\n",
    "where $t$ and $p_t$ follow the same definitions as above. For more on this scorer, refer to [Manakul et al., 2023](https://arxiv.org/abs/2303.08896).\n",
    "\n",
    "### LLM-as-a-Judge Scorers\n",
    "Under the LLM-as-a-Judge approach, either the same LLM that was used for generating the original responses or a different LLM is asked to form a judgment about a pre-generated response. Below, we define two LLM-as-a-Judge scorer templates. \n",
    "#### Categorical Judge Template (`true_false_uncertain`)\n",
    "We follow the approach proposed by [Chen & Mueller, 2023](https://arxiv.org/abs/2308.16175) in which an LLM is instructed to score a question-answer concatenation as either  *incorrect*, *uncertain*, or *correct* using a carefully constructed prompt. These categories are respectively mapped to numerical scores of 0, 0.5, and 1. We denote the LLM-as-a-judge scorers as $J: \\mathcal{Y} \\xrightarrow[]{} \\{0, 0.5, 1\\}$. Formally, we can write this scorer function as follows:\n",
    "\n",
    "\\begin{equation}\n",
    "J(y_i) = \\begin{cases}\n",
    "    0 & \\text{LLM states response is incorrect} \\\\\n",
    "    0.5 & \\text{LLM states that it is uncertain} \\\\\n",
    "    1 & \\text{LLM states response is correct}.\n",
    "\\end{cases}\n",
    "\\end{equation}\n",
    "\n",
    "#### Continuous Judge Template (`continuous`)\n",
    "For the continuous template, the LLM is asked to directly score a question-answer concatenation's correctness on a scale of 0 to 1. "
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "uqlm",
   "name": "workbench-notebooks.m126",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m126"
  },
  "kernelspec": {
   "display_name": "uqlm",
   "language": "python",
   "name": "uqlm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
