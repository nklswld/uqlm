
<!DOCTYPE html>


<html lang="en" data-content_root="../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />
    <link rel="icon" sizes="16x16" href="../../_static/images/favicon/favicon-16x16.png" type="image/png">
    <link rel="icon" sizes="32x32" href="../../_static/images/favicon/favicon-32x32.png" type="image/png">
    <link rel="apple-touch-icon" sizes="180x180" href="../../_static/images/favicon/apple-touch-icon.png" type="image/png">
    <title>Uncertainty Quantification Ensemble Demo (Advanced) &#8212; uqlm 0.3 documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=8f2a1f02" />
    <link rel="stylesheet" type="text/css" href="../../_static/nbsphinx-code-cells.css?v=2aa19091" />
    <link rel="stylesheet" type="text/css" href="../../_static/custom.css?v=662d8ef6" />
  
  <!-- So that users can add custom icons -->
  <script src="../../_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="../../_static/documentation_options.js?v=b489f392"></script>
    <script src="../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '_notebooks/examples/ensemble_demo';</script>
    <script>
        DOCUMENTATION_OPTIONS.theme_version = '0.16.1';
        DOCUMENTATION_OPTIONS.theme_switcher_json_url = 'https://cvs-health.github.io/uqlm/versions.json';
        DOCUMENTATION_OPTIONS.theme_switcher_version_match = '0.3';
        DOCUMENTATION_OPTIONS.show_version_warning_banner =
            false;
        </script>
    <link rel="icon" href="../../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class=" navbar-header-items__start">
    
      <div class="navbar-item">

  
    
  

<a class="navbar-brand logo" href="../../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../_static/horizontal_logo.png" class="logo__image only-light" alt="uqlm 0.3 documentation - Home"/>
    <img src="../../_static/horizontal_logo_no_bg.png" class="logo__image only-dark pst-js-only" alt="uqlm 0.3 documentation - Home"/>
  
  
</a></div>
    
  </div>
  
  <div class=" navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../getstarted.html">
    Get Started
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../api.html">
    API
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../index.html">
    Example Notebooks
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../contribute.html">
    Contributor Guide
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../faqs.html">
    FAQs
  </a>
</li>

  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
        </div>
      
      
        <div class="navbar-item">
<div class="version-switcher__container dropdown pst-js-only">
  <button id="pst-version-switcher-button-2"
    type="button"
    class="version-switcher__button btn btn-sm dropdown-toggle"
    data-bs-toggle="dropdown"
    aria-haspopup="listbox"
    aria-controls="pst-version-switcher-list-2"
    aria-label="Version switcher list"
  >
    Choose version  <!-- this text may get changed later by javascript -->
    <span class="caret"></span>
  </button>
  <div id="pst-version-switcher-list-2"
    class="version-switcher__menu dropdown-menu list-group-flush py-0"
    role="listbox" aria-labelledby="pst-version-switcher-button-2">
    <!-- dropdown will be populated by javascript on page load -->
  </div>
</div></div>
      
        <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
      
        <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/cvs-health/uqlm" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-square-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
</ul></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
    </div>
  

  
    <button class="pst-navbar-icon sidebar-toggle secondary-toggle" aria-label="On this page">
      <span class="fa-solid fa-outdent"></span>
    </button>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
        
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar hide-on-wide">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../getstarted.html">
    Get Started
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../api.html">
    API
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../index.html">
    Example Notebooks
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../contribute.html">
    Contributor Guide
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../faqs.html">
    FAQs
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">
<div class="version-switcher__container dropdown pst-js-only">
  <button id="pst-version-switcher-button-3"
    type="button"
    class="version-switcher__button btn btn-sm dropdown-toggle"
    data-bs-toggle="dropdown"
    aria-haspopup="listbox"
    aria-controls="pst-version-switcher-list-3"
    aria-label="Version switcher list"
  >
    Choose version  <!-- this text may get changed later by javascript -->
    <span class="caret"></span>
  </button>
  <div id="pst-version-switcher-list-3"
    class="version-switcher__menu dropdown-menu list-group-flush py-0"
    role="listbox" aria-labelledby="pst-version-switcher-button-3">
    <!-- dropdown will be populated by javascript on page load -->
  </div>
</div></div>
        
          <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
        
          <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/cvs-health/uqlm" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-square-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
</ul></div>
        
      </div>
    
  </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">

<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    <li class="breadcrumb-item active" aria-current="page"><span class="ellipsis">Uncertainty Quantification Ensemble Demo (Advanced)</span></li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="Uncertainty-Quantification-Ensemble-Demo-(Advanced)">
<h1>Uncertainty Quantification Ensemble Demo (Advanced)<a class="headerlink" href="#Uncertainty-Quantification-Ensemble-Demo-(Advanced)" title="Link to this heading">#</a></h1>
<p>Content</p>
<ol class="arabic simple">
<li><p>Introduction</p></li>
<li><p>Set up LLM and Prompts</p></li>
<li><p>Generate Responses and Confidence Scores</p></li>
<li><p>Tune Parameters</p></li>
<li><p>Performance Evaluation</p></li>
<li><p>Scorer Definitions</p></li>
</ol>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">warnings</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">precision_score</span><span class="p">,</span> <span class="n">recall_score</span><span class="p">,</span> <span class="n">f1_score</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">uqlm.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_example_dataset</span><span class="p">,</span> <span class="n">math_postprocessor</span><span class="p">,</span> <span class="n">plot_model_accuracies</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">uqlm.quantifiers</span><span class="w"> </span><span class="kn">import</span> <span class="n">UQEnsemble</span>

<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/home/jupyter/.cache/pypoetry/virtualenvs/uqlm-g7jzkC-R-py3.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html
  from .autonotebook import tqdm as notebook_tqdm
2025-03-05 18:15:53.296157: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1741198553.320653   20612 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1741198553.328239   20612 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-03-05 18:15:53.353527: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
</pre></div></div>
</div>
<p>## 1. Introduction</p>
<p>Ensemble UQ methods combine multiple individual scorers to provide a more robust and accurate uncertainty estimate. They offer high flexibility and customizability, allowing you to tailor the ensemble to specific use cases.</p>
<p><strong>Pros:</strong></p>
<ul class="simple">
<li><p>✅ <strong>Highly Flexible:</strong> Versatile and adaptable to various tasks and question types.</p></li>
<li><p>✅ <strong>Highly Customizable:</strong> Ensemble weights can be tuned for optimal performance on a specific use case.</p></li>
</ul>
<p><strong>Cons:</strong></p>
<ul class="simple">
<li><p>⚠️ <strong>Requires More Setup:</strong> Not quite “off-the-shelf”; requires some effort to configure and tune the ensemble.</p></li>
<li><p>⚠️ <strong>Best for Advanced Users:</strong> Optimizing the ensemble requires a deeper understanding of the individual scorers.</p></li>
</ul>
<p><strong>Available Scorers:</strong></p>
<ul class="simple">
<li><p>BS Detector (<a class="reference external" href="https://arxiv.org/abs/2308.16175">Chen &amp; Mueller, 2023</a>)</p></li>
<li><p>Generalized Ensemble (uses any combination of black-box, white-box, and LLM-as-a-judge scorers)</p></li>
</ul>
<p>## 2. Set up LLM and Prompts</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Loaod example dataset (SVAMP)</span>
<span class="n">svamp</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">load_example_dataset</span><span class="p">(</span><span class="s2">&quot;svamp&quot;</span><span class="p">)</span>
    <span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;question_concat&quot;</span><span class="p">:</span> <span class="s2">&quot;question&quot;</span><span class="p">,</span> <span class="s2">&quot;Answer&quot;</span><span class="p">:</span> <span class="s2">&quot;answer&quot;</span><span class="p">})[</span>
        <span class="p">[</span><span class="s2">&quot;question&quot;</span><span class="p">,</span> <span class="s2">&quot;answer&quot;</span><span class="p">]</span>
    <span class="p">]</span>
    <span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
<span class="p">)</span>
<span class="n">svamp</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Loading dataset - svamp...
Processing dataset...
Dataset ready!
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>question</th>
      <th>answer</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>There are 87 oranges and 290 bananas in Philip...</td>
      <td>145</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Marco and his dad went strawberry picking. Mar...</td>
      <td>19</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Edward spent $ 6 to buy 2 books each book cost...</td>
      <td>3</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Frank was reading through his favorite book. T...</td>
      <td>198</td>
    </tr>
    <tr>
      <th>4</th>
      <td>There were 78 dollars in Olivia's wallet. She ...</td>
      <td>63</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">svamp_tune</span> <span class="o">=</span> <span class="n">svamp</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">50</span><span class="p">]</span>
<span class="n">svamp_test</span> <span class="o">=</span> <span class="n">svamp</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">51</span><span class="p">:</span><span class="mi">100</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define prompts</span>
<span class="n">MATH_INSTRUCTION</span> <span class="o">=</span> <span class="p">(</span>
    <span class="s2">&quot;When you solve this math problem only return the answer with no additional text.</span><span class="se">\n</span><span class="s2">&quot;</span>
<span class="p">)</span>
<span class="n">tune_prompts</span> <span class="o">=</span> <span class="p">[</span><span class="n">MATH_INSTRUCTION</span> <span class="o">+</span> <span class="n">prompt</span> <span class="k">for</span> <span class="n">prompt</span> <span class="ow">in</span> <span class="n">svamp_tune</span><span class="o">.</span><span class="n">question</span><span class="p">]</span>
<span class="n">test_prompts</span> <span class="o">=</span> <span class="p">[</span><span class="n">MATH_INSTRUCTION</span> <span class="o">+</span> <span class="n">prompt</span> <span class="k">for</span> <span class="n">prompt</span> <span class="ow">in</span> <span class="n">svamp_test</span><span class="o">.</span><span class="n">question</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># User to populate .env file with API credentials</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">dotenv</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dotenv</span><span class="p">,</span> <span class="n">find_dotenv</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">langchain_openai</span><span class="w"> </span><span class="kn">import</span> <span class="n">AzureChatOpenAI</span>

<span class="n">load_dotenv</span><span class="p">(</span><span class="n">find_dotenv</span><span class="p">())</span>
<span class="n">gpt</span> <span class="o">=</span> <span class="n">AzureChatOpenAI</span><span class="p">(</span>
    <span class="n">deployment_name</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">&quot;DEPLOYMENT_NAME&quot;</span><span class="p">),</span>
    <span class="n">openai_api_key</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">&quot;API_KEY&quot;</span><span class="p">),</span>
    <span class="n">azure_endpoint</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">&quot;API_BASE&quot;</span><span class="p">),</span>
    <span class="n">openai_api_type</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">&quot;API_TYPE&quot;</span><span class="p">),</span>
    <span class="n">openai_api_version</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">&quot;API_VERSION&quot;</span><span class="p">),</span>
    <span class="n">temperature</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>  <span class="c1"># User to set temperature</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Instantiate Gemini models</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">langchain_google_vertexai</span><span class="w"> </span><span class="kn">import</span> <span class="n">ChatVertexAI</span>

<span class="n">gemini_pro</span> <span class="o">=</span> <span class="n">ChatVertexAI</span><span class="p">(</span><span class="n">model_name</span><span class="o">=</span><span class="s2">&quot;gemini-pro&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Note that although we use <code class="docutils literal notranslate"><span class="pre">ChatVertexAI</span></code> and <code class="docutils literal notranslate"><span class="pre">AzureChatOpenAI</span></code> in this example, any <a class="reference external" href="https://js.langchain.com/docs/integrations/chat/">LangChain Chat Model</a> may be used.</p>
<p>## 3. Generate responses and confidence scores</p>
<section id="UQEnsemble()---Ensemble-of-uncertainty-quantifiers-(class).">
<h2><code class="docutils literal notranslate"><span class="pre">UQEnsemble()</span></code> - Ensemble of uncertainty quantifiers (class).<a class="headerlink" href="#UQEnsemble()---Ensemble-of-uncertainty-quantifiers-(class)." title="Link to this heading">#</a></h2>
<p><strong>Class Attributes:</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">llm</span></code> (<strong>BaseChatModel, default=None</strong>) A langchain llm (<code class="docutils literal notranslate"><span class="pre">BaseChatModel</span></code>). User is responsible for specifying temperature and other relevant parameters to the constructor of their <code class="docutils literal notranslate"><span class="pre">BaseChatModel</span></code> object.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">components</span></code> - (<strong>List containing instances of BaseChatModel, LLMJudge, or elements of [“semantic_entropy”, “mean_nli”, “exact_match”, “self_reflection”, “bert_score”, “bleurt_score”, “cosine_similarity”], default=None</strong>) Specifies which UQ components to include. If None, defaults to [“semantic_entropy”, “mean_nli”, “exact_match”,”self_reflection”]=</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">device</span></code> - (<strong>str or torch.device input or torch.device object, default=”cpu”</strong>) Specifies the device that classifiers use for prediction. Set to “cuda” for classifiers to be able to leverage the GPU.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">system_prompt</span></code> - (<strong>str or None, default=”You are a helpful assistant.”</strong>) Optional argument for user to provide custom system prompt</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">max_calls_per_min</span></code> - (<strong>int, default=None</strong>) Specifies how many api calls to make per minute to avoid a rate limit error. By default, no limit is specified.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">use_n_param</span></code> (<strong>bool, default=False</strong>) Specifies whether to use <code class="docutils literal notranslate"><span class="pre">n</span></code> parameter for <code class="docutils literal notranslate"><span class="pre">BaseChatModel</span></code>. Not compatible with all <code class="docutils literal notranslate"><span class="pre">BaseChatModel</span></code> classes. If used, it speeds up the generation process substantially when <code class="docutils literal notranslate"><span class="pre">num_responses</span></code> is large.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">postprocessor</span></code> - (<strong>(str) -&gt; str, default=None</strong>) A class object to compute the self-reflection certainty score. If not provided, this method will use defined ‘langchain_llm’ with 0 temperature.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">self_reflection_generator</span></code> - (<strong>ResponseGenerator, default=None</strong>) A class object to compute the self-reflection certainty score. If not provided, this method will use defined ‘langchain_llm’ with 0 temperature.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">weights</span></code> - (<strong>list of floats, default= None</strong>) Specifies weight for each component in ensemble. If none, each component receives equal weight.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">nli_model_name</span></code> (<strong>str, default=”microsoft/deberta-large-mnli”</strong>) Specifies which NLI model to use. Must be acceptable input to <code class="docutils literal notranslate"><span class="pre">AutoTokenizer.from_pretrained()</span></code> and <code class="docutils literal notranslate"><span class="pre">AutoModelForSequenceClassification.from_pretrained()</span></code></p></li>
</ul>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>

<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>  <span class="c1"># use if GPU available</span>
<span class="c1"># device = None</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">components</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;match_score&quot;</span><span class="p">,</span>  <span class="c1"># Measures proportion of candidate responses that match original response (black-box)</span>
    <span class="s2">&quot;noncontradiction_score&quot;</span><span class="p">,</span>  <span class="c1"># mean non-contradiction probability between candidate responses and original response (black-box)</span>
    <span class="s2">&quot;normalized_probability&quot;</span><span class="p">,</span>  <span class="c1"># length-normalized joint token probability (white-box)</span>
    <span class="n">gemini_pro</span><span class="p">,</span>  <span class="c1"># LLM-as-a-judge (self)</span>
    <span class="n">gpt</span><span class="p">,</span>  <span class="c1"># LLM-as-a-judge (separate LLM)</span>
<span class="p">]</span>

<span class="n">uqe</span> <span class="o">=</span> <span class="n">UQEnsemble</span><span class="p">(</span>
    <span class="n">llm</span><span class="o">=</span><span class="n">gemini_pro</span><span class="p">,</span>
    <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span>
    <span class="n">max_calls_per_min</span><span class="o">=</span><span class="mi">250</span><span class="p">,</span>
    <span class="c1"># postprocessor=math_postprocessor,</span>
    <span class="n">use_n_param</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>  <span class="c1"># Set True if using AzureChatOpenAI for faster generation</span>
    <span class="n">components</span><span class="o">=</span><span class="n">components</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Some weights of the model checkpoint at microsoft/deberta-large-mnli were not used when initializing DebertaForSequenceClassification: [&#39;config&#39;]
- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
</pre></div></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">UQEnsemble.evaluate</span></code> - Generate responses and evaluate confidence scores on LLM responses for the provided prompts..</p>
<p><strong>Method Arguments:</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">prompts</span></code> - (<strong>list of str</strong>) A list of input prompts for the model.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">responses</span></code> - (<strong>list of str, default=None</strong>) A list of model responses for the prompts. If not provided, this method will generate responses for <code class="docutils literal notranslate"><span class="pre">self.llm</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">multiple_responses</span></code> - (<strong>list of list of str, default=None</strong>) A list of multiple model responses, each element (multiple_responses[i]) is a list of str, containing multiple model responses for prompts[i]. If not provided, this method will generate responses for <code class="docutils literal notranslate"><span class="pre">self.llm</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">mr_temperature</span></code> - (<strong>float, default=1</strong>) The <code class="docutils literal notranslate"><span class="pre">temperature</span></code> parameter for llm model to generate multiple responses</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">num_responses</span></code> - (<strong>int, default=5</strong>) The number of multiple responses used to compute observed consistency.</p></li>
</ul>
<p><strong>Returns:</strong> <code class="docutils literal notranslate"><span class="pre">UQResult</span></code> containing data (prompts, responses, and confidence scores) and metadata</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">results</span> <span class="o">=</span> <span class="k">await</span> <span class="n">uqe</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">prompts</span><span class="o">=</span><span class="n">tune_prompts</span><span class="p">,</span> <span class="n">num_responses</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">use_best</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Generating responses...
Generating candidate responses...
Computing confidence scores...
Generating LLMJudge scores...
Generating LLMJudge scores...
Computing confidence scores...
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">result_df</span> <span class="o">=</span> <span class="n">results</span><span class="o">.</span><span class="n">to_df</span><span class="p">()</span>
<span class="n">result_df</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>prompt</th>
      <th>response</th>
      <th>multiple_responses</th>
      <th>confidence_score</th>
      <th>match_score</th>
      <th>noncontradiction_score</th>
      <th>normalized_probability</th>
      <th>judge_1</th>
      <th>judge_2</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>When you solve this math problem only return t...</td>
      <td>145</td>
      <td>[145, 145, 145, 145, 145]</td>
      <td>0.698637</td>
      <td>1.0</td>
      <td>1.000000</td>
      <td>0.993186</td>
      <td>0.0</td>
      <td>0.5</td>
    </tr>
    <tr>
      <th>1</th>
      <td>When you solve this math problem only return t...</td>
      <td>19 pounds</td>
      <td>[$19$, 19 pounds., 19, 19 pounds, 19]</td>
      <td>0.445825</td>
      <td>0.2</td>
      <td>0.818286</td>
      <td>0.210841</td>
      <td>1.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>When you solve this math problem only return t...</td>
      <td>$ 3.00</td>
      <td>[$3.00, 4, 3, $ 3.00, $3 \n]</td>
      <td>0.581271</td>
      <td>0.2</td>
      <td>0.862477</td>
      <td>0.843878</td>
      <td>0.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>When you solve this math problem only return t...</td>
      <td>198</td>
      <td>[198, 198, 198, 198, 198]</td>
      <td>0.798186</td>
      <td>1.0</td>
      <td>1.000000</td>
      <td>0.990932</td>
      <td>0.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>When you solve this math problem only return t...</td>
      <td>63</td>
      <td>[$63, 63 dollars, 63, 63 dollars., 63]</td>
      <td>0.570754</td>
      <td>0.4</td>
      <td>0.964027</td>
      <td>0.489743</td>
      <td>0.0</td>
      <td>1.0</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<p>## 4. Tune Parameters</p>
</section>
<section id="Tune-parameters-and-reassess">
<h2>Tune parameters and reassess<a class="headerlink" href="#Tune-parameters-and-reassess" title="Link to this heading">#</a></h2>
<p><code class="docutils literal notranslate"><span class="pre">UQEnsemble.tune_params</span></code> - Tunes weights and threshold on a set of user-provided graded responses.</p>
<p><strong>Method Arguments:</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">correct_indicators</span></code> - (<strong>list of bool</strong>) A list of boolean indicators of whether self.original_responses are correct.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">weight_bounds</span></code> - (<strong>list of 2-tuples of floats, default = [(0,1), (0,1), (0,1), (0,1)]</strong>) Bounds of parameters for weights for scipy minimize function. Order must correspond to order of self.components.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">weights_objective</span></code> - (<strong>{‘fbeta_score’, ‘accuracy_score’, ‘balanced_accuracy_score’, ‘roc_auc’, ‘log_loss’}, default=’roc_auc’</strong>) Objective function for optimization of alpha and beta. Must match thresh_objective if one of ‘fbeta_score’,</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">thresh_bounds</span></code> - (<strong>tuple of floats, default=(0,1)</strong>) Bounds to search for threshold</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">thresh_objective</span></code> - (<strong>{‘fbeta_score’, ‘accuracy_score’, ‘balanced_accuracy_score’, ‘roc_auc’, ‘log_loss’}, default=’fbeta_score’</strong>) Objective function for threshold optimization via grid search.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">n_trials</span></code> - (<strong>int, default=100</strong>) Indicates how many candidates to search over with optuna optimizer</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">grid_search_alpha_beta</span></code> - (<strong>bool, default=False</strong>) Indicates whether to conduct grid search as optimization routine for alpha and beta</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">step_size</span></code> - (<strong>float, default=0.01</strong>) Indicates step size in grid search, if used</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">fscore_beta</span></code> - (<strong>float, default=1</strong>) Value of beta in fbeta_score</p></li>
</ul>
<p><strong>Returns:</strong> Instance of UQEnsembleResult, containing data (prompts, responses, and confidence scores) and metadata (parameters, etc.)</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Populate correct answers and grade responses</span>
<span class="n">correct_indicators</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">math_postprocessor</span><span class="p">(</span><span class="n">r</span><span class="p">)</span> <span class="o">==</span> <span class="n">a</span>
    <span class="k">for</span> <span class="n">r</span><span class="p">,</span> <span class="n">a</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">result_df</span><span class="p">[</span><span class="s2">&quot;response&quot;</span><span class="p">],</span> <span class="n">svamp_tune</span><span class="p">[</span><span class="s2">&quot;answer&quot;</span><span class="p">])</span>
<span class="p">]</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tuned_result</span> <span class="o">=</span> <span class="n">uqe</span><span class="o">.</span><span class="n">tune_params</span><span class="p">(</span>
    <span class="n">correct_indicators</span><span class="o">=</span><span class="n">correct_indicators</span><span class="p">,</span> <span class="n">weights_objective</span><span class="o">=</span><span class="s2">&quot;roc_auc&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Optimizing weights...
Optimizing threshold with grid search...
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># View optimized_weights</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">weight</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">uqe</span><span class="o">.</span><span class="n">weights</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Weight for </span><span class="si">{</span><span class="n">uqe</span><span class="o">.</span><span class="n">component_names</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">weight</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Weight for match_score: 0.31101559912033366
Weight for noncontradiction_score: 0.28149817493332807
Weight for normalized_probability: 0.3174254003685539
Weight for judge_1: 0.006798364703485985
Weight for judge_2: 0.08326246087429848
</pre></div></div>
</div>
<p>## 5. Evaluate Performance</p>
<p>To evaluate performance, we will generate responses and corresponding confidence scores on a holdout set using the tuned ensemble.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">test_results</span> <span class="o">=</span> <span class="k">await</span> <span class="n">uqe</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">prompts</span><span class="o">=</span><span class="n">test_prompts</span><span class="p">,</span> <span class="n">num_responses</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">use_best</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Generating responses...
Generating candidate responses...
Computing confidence scores...
Generating LLMJudge scores...
Generating LLMJudge scores...
Computing confidence scores...
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">test_result_df</span> <span class="o">=</span> <span class="n">test_results</span><span class="o">.</span><span class="n">to_df</span><span class="p">()</span>
<span class="n">test_result_df</span><span class="p">[</span><span class="s2">&quot;response_correct&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">math_postprocessor</span><span class="p">(</span><span class="n">r</span><span class="p">)</span> <span class="o">==</span> <span class="n">a</span>
    <span class="k">for</span> <span class="n">r</span><span class="p">,</span> <span class="n">a</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">test_result_df</span><span class="p">[</span><span class="s2">&quot;response&quot;</span><span class="p">],</span> <span class="n">svamp_test</span><span class="p">[</span><span class="s2">&quot;answer&quot;</span><span class="p">])</span>
<span class="p">]</span>
<span class="n">test_result_df</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>prompt</th>
      <th>response</th>
      <th>multiple_responses</th>
      <th>confidence_score</th>
      <th>match_score</th>
      <th>noncontradiction_score</th>
      <th>normalized_probability</th>
      <th>judge_1</th>
      <th>judge_2</th>
      <th>response_correct</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>When you solve this math problem only return t...</td>
      <td>1</td>
      <td>[1, 1, 1, 1, 1]</td>
      <td>0.908257</td>
      <td>1.0</td>
      <td>1.000000</td>
      <td>0.994699</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>True</td>
    </tr>
    <tr>
      <th>1</th>
      <td>When you solve this math problem only return t...</td>
      <td>27</td>
      <td>[27, 27, 27, 27, 87]</td>
      <td>0.801006</td>
      <td>0.8</td>
      <td>0.821439</td>
      <td>0.989717</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>True</td>
    </tr>
    <tr>
      <th>2</th>
      <td>When you solve this math problem only return t...</td>
      <td>4</td>
      <td>[4, 4, 4, 4, 4]</td>
      <td>0.995645</td>
      <td>1.0</td>
      <td>1.000000</td>
      <td>0.986279</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>True</td>
    </tr>
    <tr>
      <th>3</th>
      <td>When you solve this math problem only return t...</td>
      <td>17</td>
      <td>[27, 17, 17, 17, 17]</td>
      <td>0.563772</td>
      <td>0.8</td>
      <td>0.827284</td>
      <td>0.258584</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>True</td>
    </tr>
    <tr>
      <th>4</th>
      <td>When you solve this math problem only return t...</td>
      <td>16</td>
      <td>[16 \n, 16, 16, 16, 22\n]</td>
      <td>0.730174</td>
      <td>0.6</td>
      <td>0.815858</td>
      <td>0.967482</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>False</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;&quot;&quot;Baseline LLM accuracy: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">test_result_df</span><span class="p">[</span><span class="s2">&quot;response_correct&quot;</span><span class="p">])</span><span class="si">}</span><span class="s2">&quot;&quot;&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Baseline LLM accuracy: 0.6530612244897959
</pre></div></div>
</div>
<p>Next we will plot filtered LLM accuracy at various confidence score thresholds. The idea is to measure the LLM’s performance when we consider responses with confidence scores above a given threshold.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_model_accuracies</span><span class="p">(</span>
    <span class="n">scores</span><span class="o">=</span><span class="n">test_result_df</span><span class="o">.</span><span class="n">confidence_score</span><span class="p">,</span>
    <span class="n">correct_indicators</span><span class="o">=</span><span class="n">test_result_df</span><span class="o">.</span><span class="n">response_correct</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/_notebooks_examples_ensemble_demo_31_0.png" src="../../_images/_notebooks_examples_ensemble_demo_31_0.png" />
</div>
</div>
<p>Lastly, we will compute the optimal threshold for binarizing confidence scores, using F1-score as the objective. Using this threshold, we can compute precision, recall, and F1-score for semantic entropy predictions of whether responses are correct.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># extract optimal threshold</span>
<span class="n">best_threshold</span> <span class="o">=</span> <span class="n">uqe</span><span class="o">.</span><span class="n">thresh</span>

<span class="c1"># Define score vector and corresponding correct indicators (i.e. ground truth)</span>
<span class="n">y_scores</span> <span class="o">=</span> <span class="n">test_result_df</span><span class="p">[</span><span class="s2">&quot;confidence_score&quot;</span><span class="p">]</span>  <span class="c1"># confidence score</span>
<span class="n">correct_indicators</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">test_result_df</span><span class="o">.</span><span class="n">response_correct</span>
<span class="p">)</span> <span class="o">*</span> <span class="mi">1</span>  <span class="c1"># Whether responses is actually correct</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">(</span><span class="n">s</span> <span class="o">&gt;</span> <span class="n">best_threshold</span><span class="p">)</span> <span class="o">*</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">y_scores</span>
<span class="p">]</span>  <span class="c1"># predicts whether response is correct based on confidence score</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Ensemble F1-optimal threshold: </span><span class="si">{</span><span class="n">best_threshold</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Ensemble F1-optimal threshold: 0.4
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[19]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># evaluate precision, recall, and f1-score of semantic entropy predictions of correctness</span>
<span class="nb">print</span><span class="p">(</span>
    <span class="sa">f</span><span class="s2">&quot;Ensemble precision: </span><span class="si">{</span><span class="n">precision_score</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">correct_indicators</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred</span><span class="o">=</span><span class="n">y_pred</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Ensemble recall: </span><span class="si">{</span><span class="n">recall_score</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">correct_indicators</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred</span><span class="o">=</span><span class="n">y_pred</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Ensemble f1-score: </span><span class="si">{</span><span class="n">f1_score</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">correct_indicators</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred</span><span class="o">=</span><span class="n">y_pred</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Ensemble precision: 0.7317073170731707
Ensemble recall: 0.9375
Ensemble f1-score: 0.821917808219178
</pre></div></div>
</div>
<p>## 6. Scorer Definitions</p>
<section id="Black-Box-Scorers">
<h3>Black-Box Scorers<a class="headerlink" href="#Black-Box-Scorers" title="Link to this heading">#</a></h3>
<p>Black-Box UQ scorers exploit variation in LLM responses to the same prompt to measure semantic consistency. All scorers have outputs ranging from 0 to 1, with higher values indicating higher confidence.</p>
<p>For a given prompt <span class="math notranslate nohighlight">\(x_i\)</span>, these approaches involves generating <span class="math notranslate nohighlight">\(m\)</span> responses <span class="math notranslate nohighlight">\(\tilde{\mathbf{y}}_i = \{ \tilde{y}_{i1},...,\tilde{y}_{im}\}\)</span>, using a non-zero temperature, from the same prompt and comparing these responses to the original response <span class="math notranslate nohighlight">\(y_{i}\)</span>. We provide detailed descriptions of each below.</p>
</section>
</section>
<section id="Exact-Match-Rate-(match_score)">
<h2>Exact Match Rate (<code class="docutils literal notranslate"><span class="pre">match_score</span></code>)<a class="headerlink" href="#Exact-Match-Rate-(match_score)" title="Link to this heading">#</a></h2>
<p>Exact Match Rate (EMR) computes the proportion of candidate responses that are identical to the original response.</p>
<div class="math notranslate nohighlight">
\[EMR(y_i; \tilde{\mathbf{y}}_i) = \frac{1}{m} \sum_{j=1}^m \mathbb{I}(y_i=\tilde{y}_{ij}).\]</div>
<p>For more on this scorer, refer to <a class="reference external" href="https://arxiv.org/abs/2305.14613">Cole et al., 2023</a>.</p>
</section>
<section id="Non-Contradiction-Probability-(noncontradiction_score)">
<h2>Non-Contradiction Probability (<code class="docutils literal notranslate"><span class="pre">noncontradiction_score</span></code>)<a class="headerlink" href="#Non-Contradiction-Probability-(noncontradiction_score)" title="Link to this heading">#</a></h2>
<p>Non-contradiction probability (NCP) computes the mean non-contradiction probability estimated by a natural language inference (NLI) model. This score is formally defined as follows:</p>
<dl class="simple">
<dt>:nbsphinx-math:<a href="#id1"><span class="problematic" id="id2">`</span></a>begin{equation}</dt><dd><p>NCP(y_i; tilde{mathbf{y}}_i) = frac{1}{m} sum_{j=1}^m(1 - p_j)</p>
</dd>
</dl>
<p>end{equation}` where</p>
<dl class="simple">
<dt>:nbsphinx-math:<a href="#id3"><span class="problematic" id="id4">`</span></a>begin{equation}</dt><dd><p>p_j = frac{eta(y_{i}, tilde{y}_{ij}) + eta(tilde{y}_{ij},y_i)}{2}.</p>
</dd>
</dl>
<p>end{equation}`</p>
<p>Above, <span class="math notranslate nohighlight">\(\eta(\tilde{y}_{ij},y_i)\)</span> denotes the contradiction probability estimated by the NLI model for response <span class="math notranslate nohighlight">\(y_i\)</span> and candidate <span class="math notranslate nohighlight">\(\tilde{y}_{ij}\)</span>. For more on this scorer, refer to <a class="reference external" href="https://arxiv.org/abs/2308.16175">Chen &amp; Mueller, 2023</a>, <a class="reference external" href="https://arxiv.org/abs/2305.19187">Lin et al., 2025</a>, or <a class="reference external" href="https://arxiv.org/abs/2303.08896">Manakul et al., 2023</a>.</p>
</section>
<section id="Normalized-Semantic-Negentropy-(entropy_score)">
<h2>Normalized Semantic Negentropy (<code class="docutils literal notranslate"><span class="pre">entropy_score</span></code>)<a class="headerlink" href="#Normalized-Semantic-Negentropy-(entropy_score)" title="Link to this heading">#</a></h2>
<p>Normalized Semantic Negentropy (NSN) normalizes the standard computation of discrete semantic entropy to be increasing with higher confidence and have [0,1] support. In contrast to the EMR and NCP, semantic entropy does not distinguish between an original response and candidate responses. Instead, this approach computes a single metric value on a list of responses generated from the same prompt. Under this approach, responses are clustered using an NLI model based on mutual entailment. We
consider the discrete version of SE, where the final set of clusters is defined as follows:</p>
<dl class="simple">
<dt>:nbsphinx-math:<a href="#id5"><span class="problematic" id="id6">`</span></a>begin{equation}</dt><dd><p>SE(y_i; tilde{mathbf{y}}_i) = - sum_{C in mathcal{C}} P(C|y_i, tilde{mathbf{y}}_i)log P(C|y_i, tilde{mathbf{y}}_i),</p>
</dd>
</dl>
<p>end{equation}` where <span class="math notranslate nohighlight">\(P(C|y_i, \tilde{\mathbf{y}}_i)\)</span> denotes the probability a randomly selected response $y <span class="math">\in `{y_i} :nbsphinx-math:</span>cup <cite>:nbsphinx-math:</cite>tilde{mathbf{y}}`_i $ belongs to cluster <span class="math notranslate nohighlight">\(C\)</span>, and <span class="math notranslate nohighlight">\(\mathcal{C}\)</span> denotes the full set of clusters of <span class="math notranslate nohighlight">\(\{y_i\} \cup \tilde{\mathbf{y}}_i\)</span>.</p>
<dl class="simple">
<dt>To ensure that we have a normalized confidence score with <span class="math notranslate nohighlight">\([0,1]\)</span> support and with higher values corresponding to higher confidence, we implement the following normalization to arrive at <span class="math">\textit{Normalized Semantic Negentropy}</span> (NSN): :nbsphinx-math:<a href="#id7"><span class="problematic" id="id8">`</span></a>begin{equation}</dt><dd><p>NSN(y_i; tilde{mathbf{y}}_i) = 1 - frac{SE(y_i; tilde{mathbf{y}}_i)}{log m},</p>
</dd>
</dl>
<p>end{equation}` where <span class="math notranslate nohighlight">\(\log m\)</span> is included to normalize the support.</p>
</section>
<section id="BERTScore-(bert_score)">
<h2>BERTScore (<code class="docutils literal notranslate"><span class="pre">bert_score</span></code>)<a class="headerlink" href="#BERTScore-(bert_score)" title="Link to this heading">#</a></h2>
<p>Let a tokenized text sequence be denoted as <span class="math notranslate nohighlight">\(\textbf{t} = \{t_1,...t_L\}\)</span> and the corresponding contextualized word embeddings as <span class="math notranslate nohighlight">\(\textbf{E} = \{\textbf{e}_1,...,\textbf{e}_L\}\)</span>, where <span class="math notranslate nohighlight">\(L\)</span> is the number of tokens in the text. The BERTScore precision, recall, and F1-scores between two tokenized texts <span class="math notranslate nohighlight">\(\textbf{t}, \textbf{t}'\)</span> are respectively defined as follows:</p>
<dl class="simple">
<dt>:nbsphinx-math:<a href="#id9"><span class="problematic" id="id10">`</span></a>begin{equation}</dt><dd><p>BertP(textbf{t}, textbf{t}’) = frac{1}{| textbf{t}|} sum_{t in textbf{t}} max_{t’ in textbf{t}’} textbf{e} cdot textbf{e}’</p>
</dd>
</dl>
<p>end{equation}`</p>
<dl class="simple">
<dt>:nbsphinx-math:<a href="#id11"><span class="problematic" id="id12">`</span></a>begin{equation}</dt><dd><p>BertR(textbf{t}, textbf{t}’) = frac{1}{| textbf{t}’<a href="#id13"><span class="problematic" id="id14">|</span></a>} sum_{t’ in textbf{t}’} max_{t in textbf{t}} textbf{e} cdot textbf{e}’</p>
</dd>
</dl>
<p>end{equation}`</p>
<dl class="simple">
<dt>:nbsphinx-math:<a href="#id15"><span class="problematic" id="id16">`</span></a>begin{equation}</dt><dd><p>BertF(textbf{t}, textbf{t}’) = 2frac{ BertP(textbf{t}, textbf{t}’)  BertR(textbf{t}, textbf{t}’)}{BertPr(textbf{t}, textbf{t}’)  + BertRec(textbf{t}, textbf{t}’)},</p>
</dd>
<dt>end{equation}` where <span class="math notranslate nohighlight">\(e, e'\)</span> respectively correspond to <span class="math notranslate nohighlight">\(t, t'\)</span>. We compute our BERTScore-based confidence scores as follows: :nbsphinx-math:<a href="#id17"><span class="problematic" id="id18">`</span></a>begin{equation}</dt><dd><p>BertConfidence(y_i; tilde{mathbf{y}}_i) = frac{1}{m} sum_{j=1}^m BertF(y_i, tilde{y}_{ij}),</p>
</dd>
</dl>
<p>end{equation}` i.e. the average BERTScore F1 across pairings of the original response with all candidate responses. For more on BERTScore, refer to <a class="reference external" href="https://arxiv.org/abs/1904.09675">Zheng et al., 2020</a>.</p>
</section>
<section id="BLEURT-(bleurt_score)">
<h2>BLEURT (<code class="docutils literal notranslate"><span class="pre">bleurt_score</span></code>)<a class="headerlink" href="#BLEURT-(bleurt_score)" title="Link to this heading">#</a></h2>
<p>In contrast to the aforementioned scorers, BLEURT is specifically pre-trained and fine-tuned to learn human judgments of text similarity.\footnote{We use the recommended BLEURT checkpoint of <span class="math">\texttt{BLEURT-20}</span>. Our BLEURT confidence score is the average BLEURT value across pairings of the original response with all candidate responses:</p>
<dl class="simple">
<dt>:nbsphinx-math:<a href="#id19"><span class="problematic" id="id20">`</span></a>begin{equation}</dt><dd><p>BLEURTConfidence(y_i; tilde{mathbf{y}}_i) = frac{1}{m} sum_{j=1}^m BLEURT(y_i, tilde{y}_{ij}).</p>
</dd>
</dl>
<p>end{equation}`</p>
<p>For more on this scorer, refer to <a class="reference external" href="https://arxiv.org/abs/2004.04696">Sellam et al., 2020</a>.</p>
</section>
<section id="Normalized-Cosine-Similarity-(cosine_scorer)">
<h2>Normalized Cosine Similarity (<code class="docutils literal notranslate"><span class="pre">cosine_scorer</span></code>)<a class="headerlink" href="#Normalized-Cosine-Similarity-(cosine_scorer)" title="Link to this heading">#</a></h2>
<p>This scorer leverages a sentence transformer to map LLM outputs to an embedding space and measure similarity using those sentence embeddings. Let <span class="math notranslate nohighlight">\(V: \mathcal{Y} \xrightarrow{} \mathbb{R}^d\)</span> denote the sentence transformer, where <span class="math notranslate nohighlight">\(d\)</span> is the dimension of the embedding space. The average cosine similarity across pairings of the original response with all candidate responses is given as follows:</p>
<dl class="simple">
<dt>:nbsphinx-math:<a href="#id21"><span class="problematic" id="id22">`</span></a>begin{equation}</dt><dd><p>CS(y_i; tilde{mathbf{y}}_i) = frac{1}{m} sum_{i=1}^m   frac{mathbf{V}(y_i) cdot mathbf{V}(tilde{y}_{ij}) }{ lVert mathbf{V}(y_i) rVert lVert mathbf{V}(tilde{y}_{ij}) rVert}.</p>
</dd>
</dl>
<p>end{equation}`</p>
<p>To ensure a standardized support of <span class="math notranslate nohighlight">\([0, 1]\)</span>, we normalize cosine similarity to obtain confidence scores as follows:</p>
<dl class="simple">
<dt>:nbsphinx-math:<a href="#id23"><span class="problematic" id="id24">`</span></a>begin{equation}</dt><dd><p>NCS(y_i; tilde{mathbf{y}}_i) = frac{CS(y_i; tilde{mathbf{y}}_i) + 1}{2}.</p>
</dd>
</dl>
<p>end{equation}`</p>
<section id="White-Box-UQ-Scorers">
<h3>White-Box UQ Scorers<a class="headerlink" href="#White-Box-UQ-Scorers" title="Link to this heading">#</a></h3>
<p>White-box UQ scorers leverage token probabilities of the LLM’s generated response to quantify uncertainty. All scorers have outputs ranging from 0 to 1, with higher values indicating higher confidence. We define two white-box UQ scorers below.</p>
</section>
</section>
<section id="Length-Normalized-Token-Probability-(normalized_probability)">
<h2>Length-Normalized Token Probability (<code class="docutils literal notranslate"><span class="pre">normalized_probability</span></code>)<a class="headerlink" href="#Length-Normalized-Token-Probability-(normalized_probability)" title="Link to this heading">#</a></h2>
<p>Let the tokenization LLM response <span class="math notranslate nohighlight">\(y_i\)</span> be denoted as <span class="math notranslate nohighlight">\(\{t_1,...,t_{L_i}\}\)</span>, where <span class="math notranslate nohighlight">\(L_i\)</span> denotes the number of tokens the response. Length-normalized token probability (LNTP) computes a length-normalized analog of joint token probability:</p>
<dl class="simple">
<dt>:nbsphinx-math:<a href="#id25"><span class="problematic" id="id26">`</span></a>begin{equation}</dt><dd><p>LNTP(y_i) = prod_{t in y_i}  p_t^{L_i},</p>
</dd>
</dl>
<p>end{equation}` where <span class="math notranslate nohighlight">\(p_t\)</span> denotes the token probability for token <span class="math notranslate nohighlight">\(t\)</span>. Note that this score is equivalent to the geometric mean of token probabilities for response <span class="math notranslate nohighlight">\(y_i\)</span>. For more on this scorer, refer to <a class="reference external" href="https://arxiv.org/pdf/2002.07650">Malinin &amp; Gales, 2021</a>.</p>
</section>
<section id="Minimum-Token-Probability-(min_probability)">
<h2>Minimum Token Probability (<code class="docutils literal notranslate"><span class="pre">min_probability</span></code>)<a class="headerlink" href="#Minimum-Token-Probability-(min_probability)" title="Link to this heading">#</a></h2>
<p>Minimum token probability (MTP) uses the minimum among token probabilities for a given responses as a confidence score:</p>
<dl class="simple">
<dt>:nbsphinx-math:<a href="#id27"><span class="problematic" id="id28">`</span></a>begin{equation}</dt><dd><p>MTP(y_i) = min_{t in y_i}  p_t,</p>
</dd>
</dl>
<p>end{equation}` where <span class="math notranslate nohighlight">\(t\)</span> and <span class="math notranslate nohighlight">\(p_t\)</span> follow the same definitions as above. For more on this scorer, refer to <a class="reference external" href="https://arxiv.org/abs/2303.08896">Manakul et al., 2023</a>.</p>
<section id="LLM-as-a-Judge-Scorers">
<h3>LLM-as-a-Judge Scorers<a class="headerlink" href="#LLM-as-a-Judge-Scorers" title="Link to this heading">#</a></h3>
<p>Under the LLM-as-a-Judge approach, either the same LLM that was used for generating the original responses or a different LLM is asked to form a judgment about a pre-generated response. Below, we define two LLM-as-a-Judge scorer templates. #### Categorical Judge Template (<code class="docutils literal notranslate"><span class="pre">true_false_uncertain</span></code>) We follow the approach proposed by <a class="reference external" href="https://arxiv.org/abs/2308.16175">Chen &amp; Mueller, 2023</a> in which an LLM is instructed to score a question-answer concatenation as either <em>incorrect</em>, <em>uncertain</em>,
or <em>correct</em> using a carefully constructed prompt. These categories are respectively mapped to numerical scores of 0, 0.5, and 1. We denote the LLM-as-a-judge scorers as <span class="math notranslate nohighlight">\(J: \mathcal{Y} \xrightarrow[]{} \{0, 0.5, 1\}\)</span>. Formally, we can write this scorer function as follows:</p>
<p>:nbsphinx-math:<a href="#id29"><span class="problematic" id="id30">`</span></a>begin{equation}
J(y_i) = begin{cases}</p>
<blockquote>
<div><p>0 &amp; text{LLM states response is incorrect} \
0.5 &amp; text{LLM states that it is uncertain} \
1 &amp; text{LLM states response is correct}.</p>
</div></blockquote>
<p>end{cases}
end{equation}`</p>
</section>
</section>
<section id="Continuous-Judge-Template-(continuous)">
<h2>Continuous Judge Template (<code class="docutils literal notranslate"><span class="pre">continuous</span></code>)<a class="headerlink" href="#Continuous-Judge-Template-(continuous)" title="Link to this heading">#</a></h2>
<p>For the continuous template, the LLM is asked to directly score a question-answer concatenation’s correctness on a scale of 0 to 1.</p>
</section>
</section>


                </article>
              
              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
<div
    id="pst-page-navigation-heading-2"
    class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc" aria-labelledby="pst-page-navigation-heading-2">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#UQEnsemble()---Ensemble-of-uncertainty-quantifiers-(class)."><code class="docutils literal notranslate"><span class="pre">UQEnsemble()</span></code> - Ensemble of uncertainty quantifiers (class).</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Tune-parameters-and-reassess">Tune parameters and reassess</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#Black-Box-Scorers">Black-Box Scorers</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Exact-Match-Rate-(match_score)">Exact Match Rate (<code class="docutils literal notranslate"><span class="pre">match_score</span></code>)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Non-Contradiction-Probability-(noncontradiction_score)">Non-Contradiction Probability (<code class="docutils literal notranslate"><span class="pre">noncontradiction_score</span></code>)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Normalized-Semantic-Negentropy-(entropy_score)">Normalized Semantic Negentropy (<code class="docutils literal notranslate"><span class="pre">entropy_score</span></code>)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#BERTScore-(bert_score)">BERTScore (<code class="docutils literal notranslate"><span class="pre">bert_score</span></code>)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#BLEURT-(bleurt_score)">BLEURT (<code class="docutils literal notranslate"><span class="pre">bleurt_score</span></code>)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Normalized-Cosine-Similarity-(cosine_scorer)">Normalized Cosine Similarity (<code class="docutils literal notranslate"><span class="pre">cosine_scorer</span></code>)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#White-Box-UQ-Scorers">White-Box UQ Scorers</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Length-Normalized-Token-Probability-(normalized_probability)">Length-Normalized Token Probability (<code class="docutils literal notranslate"><span class="pre">normalized_probability</span></code>)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Minimum-Token-Probability-(min_probability)">Minimum Token Probability (<code class="docutils literal notranslate"><span class="pre">min_probability</span></code>)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#LLM-as-a-Judge-Scorers">LLM-as-a-Judge Scorers</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Continuous-Judge-Template-(continuous)">Continuous Judge Template (<code class="docutils literal notranslate"><span class="pre">continuous</span></code>)</a></li>
</ul>
  </nav></div>

  <div class="sidebar-secondary-item">
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="../../_sources/_notebooks/examples/ensemble_demo.ipynb.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
      © Copyright 2025, CVS Health.
      <br/>
    
  </p>
</div>
      
        <div class="footer-item">

  <p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 7.4.7.
    <br/>
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="theme-version">
  <!-- # L10n: Setting the PST URL as an argument as this does not need to be localized -->
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.16.1.
</p></div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>