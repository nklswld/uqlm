
<!DOCTYPE html>


<html lang="en" data-content_root="../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />
    <link rel="icon" sizes="16x16" href="../../_static/images/favicon/favicon-16x16.png" type="image/png">
    <link rel="icon" sizes="32x32" href="../../_static/images/favicon/favicon-32x32.png" type="image/png">
    <link rel="apple-touch-icon" sizes="180x180" href="../../_static/images/favicon/apple-touch-icon.png" type="image/png">
    <title>🎯 Tunable Ensemble for LLM Uncertainty (Advanced) &#8212; uqlm 0.3 documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=8f2a1f02" />
    <link rel="stylesheet" type="text/css" href="../../_static/nbsphinx-code-cells.css?v=2aa19091" />
    <link rel="stylesheet" type="text/css" href="../../_static/custom.css?v=662d8ef6" />
  
  <!-- So that users can add custom icons -->
  <script src="../../_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="../../_static/documentation_options.js?v=b489f392"></script>
    <script src="../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '_notebooks/examples/ensemble_tuning_demo';</script>
    <script>
        DOCUMENTATION_OPTIONS.theme_version = '0.16.1';
        DOCUMENTATION_OPTIONS.theme_switcher_json_url = 'https://cvs-health.github.io/uqlm/versions.json';
        DOCUMENTATION_OPTIONS.theme_switcher_version_match = '0.3';
        DOCUMENTATION_OPTIONS.show_version_warning_banner =
            false;
        </script>
    <link rel="icon" href="../../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="🎯 LLM-as-a-Judge" href="judges_demo.html" />
    <link rel="prev" title="🎯 BS Detector: Off-the-Shelf Ensemble for LLM Uncertainty" href="ensemble_off_the_shelf_demo.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class=" navbar-header-items__start">
    
      <div class="navbar-item">

  
    
  

<a class="navbar-brand logo" href="../../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../_static/horizontal_logo.png" class="logo__image only-light" alt="uqlm 0.3 documentation - Home"/>
    <img src="../../_static/horizontal_logo_no_bg.png" class="logo__image only-dark pst-js-only" alt="uqlm 0.3 documentation - Home"/>
  
  
</a></div>
    
  </div>
  
  <div class=" navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../getstarted.html">
    Get Started
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../api.html">
    API
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="../index.html">
    Example Notebooks
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../contribute.html">
    Contributor Guide
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../faqs.html">
    FAQs
  </a>
</li>

  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
        </div>
      
      
        <div class="navbar-item">
<div class="version-switcher__container dropdown pst-js-only">
  <button id="pst-version-switcher-button-2"
    type="button"
    class="version-switcher__button btn btn-sm dropdown-toggle"
    data-bs-toggle="dropdown"
    aria-haspopup="listbox"
    aria-controls="pst-version-switcher-list-2"
    aria-label="Version switcher list"
  >
    Choose version  <!-- this text may get changed later by javascript -->
    <span class="caret"></span>
  </button>
  <div id="pst-version-switcher-list-2"
    class="version-switcher__menu dropdown-menu list-group-flush py-0"
    role="listbox" aria-labelledby="pst-version-switcher-button-2">
    <!-- dropdown will be populated by javascript on page load -->
  </div>
</div></div>
      
        <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
      
        <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/cvs-health/uqlm" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-square-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
</ul></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
    </div>
  

  
    <button class="pst-navbar-icon sidebar-toggle secondary-toggle" aria-label="On this page">
      <span class="fa-solid fa-outdent"></span>
    </button>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../getstarted.html">
    Get Started
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../api.html">
    API
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="../index.html">
    Example Notebooks
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../contribute.html">
    Contributor Guide
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../faqs.html">
    FAQs
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">
<div class="version-switcher__container dropdown pst-js-only">
  <button id="pst-version-switcher-button-3"
    type="button"
    class="version-switcher__button btn btn-sm dropdown-toggle"
    data-bs-toggle="dropdown"
    aria-haspopup="listbox"
    aria-controls="pst-version-switcher-list-3"
    aria-label="Version switcher list"
  >
    Choose version  <!-- this text may get changed later by javascript -->
    <span class="caret"></span>
  </button>
  <div id="pst-version-switcher-list-3"
    class="version-switcher__menu dropdown-menu list-group-flush py-0"
    role="listbox" aria-labelledby="pst-version-switcher-button-3">
    <!-- dropdown will be populated by javascript on page load -->
  </div>
</div></div>
        
          <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
        
          <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/cvs-health/uqlm" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-square-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
</ul></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
<nav class="bd-docs-nav bd-links"
     aria-label="Section Navigation">
  <p class="bd-links__title" role="heading" aria-level="1">Section Navigation</p>
  <div class="bd-toc-item navbar-nav"><ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="ensemble_off_the_shelf_demo.html">🎯 BS Detector: Off-the-Shelf Ensemble for LLM Uncertainty</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">🎯 Tunable Ensemble for LLM Uncertainty (Advanced)</a></li>
<li class="toctree-l1"><a class="reference internal" href="judges_demo.html">🎯 LLM-as-a-Judge</a></li>
<li class="toctree-l1"><a class="reference internal" href="semantic_entropy_demo.html">🎯 Semantic Entropy</a></li>
<li class="toctree-l1"><a class="reference internal" href="white_box_demo.html">🎯 White-Box Uncertainty Quantification</a></li>
<li class="toctree-l1"><a class="reference internal" href="black_box_demo.html">🎯 Black-Box Uncertainty Quantification</a></li>
</ul>
</div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">

<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="../index.html" class="nav-link">Example Notebooks</a></li>
    
    <li class="breadcrumb-item active" aria-current="page"><span class="ellipsis">🎯 Tunable Ensemble for LLM Uncertainty (Advanced)</span></li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="🎯-Tunable-Ensemble-for-LLM-Uncertainty-(Advanced)">
<h1>🎯 Tunable Ensemble for LLM Uncertainty (Advanced)<a class="headerlink" href="#🎯-Tunable-Ensemble-for-LLM-Uncertainty-(Advanced)" title="Link to this heading">#</a></h1>
<div style="background-color: rgba(200, 200, 200, 0.1); padding: 20px; border-radius: 8px; margin-bottom: 20px; border: 1px solid rgba(127, 127, 127, 0.2); max-width: 97.5%; overflow-wrap: break-word;"><p style="font-size: 16px; line-height: 1.6"><p>Ensemble UQ methods combine multiple individual scorers to provide a more robust uncertainty estimate. They offer high flexibility and customizability, allowing you to tailor the ensemble to specific use cases. This ensemble can leverage any combination of black-box, white-box, or LLM-as-a-Judge scorers offered by uqlm. Below is a list of the available scorers:</p>
<section id="Black-Box-(Consistency)-Scorers">
<h2>Black-Box (Consistency) Scorers<a class="headerlink" href="#Black-Box-(Consistency)-Scorers" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Non-Contradiction Probability (<a class="reference external" href="https://arxiv.org/abs/2308.16175">Chen &amp; Mueller, 2023</a>; <a class="reference external" href="https://arxiv.org/abs/2305.19187">Lin et al., 2025</a>; <a class="reference external" href="https://arxiv.org/abs/2303.08896">Manakul et al., 2023</a>)</p></li>
<li><p>Semantic Negentropy (based on <a class="reference external" href="https://www.nature.com/articles/s41586-024-07421-0">Farquhar et al., 2024</a>; <a class="reference external" href="https://arxiv.org/pdf/2302.09664">Kuhn et al., 2023</a>)</p></li>
<li><p>Exact Match (<a class="reference external" href="https://arxiv.org/abs/2305.14613">Cole et al., 2023</a>; <a class="reference external" href="https://arxiv.org/abs/2308.16175">Chen &amp; Mueller, 2023</a>)</p></li>
<li><p>BERT-score (<a class="reference external" href="https://arxiv.org/abs/2303.08896">Manakul et al., 2023</a>; <a class="reference external" href="https://arxiv.org/abs/1904.09675">Zheng et al., 2020</a>)</p></li>
<li><p>BLUERT (<a class="reference external" href="https://arxiv.org/abs/2004.04696">Sellam et al., 2020</a>)</p></li>
<li><p>Normalized Cosine Similarity (<a class="reference external" href="https://arxiv.org/pdf/2412.05563">Shorinwa et al., 2024</a>; <a class="reference external" href="https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2">HuggingFace</a>)</p></li>
</ul>
</section>
<section id="White-Box-(Token-Probability-Based)-Scorers">
<h2>White-Box (Token-Probability-Based) Scorers<a class="headerlink" href="#White-Box-(Token-Probability-Based)-Scorers" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Minimum token probability (<a class="reference external" href="https://arxiv.org/abs/2303.08896">Manakul et al., 2023</a>)</p></li>
<li><p>Length-Normalized Joint Token Probability (<a class="reference external" href="https://arxiv.org/pdf/2002.07650">Malinin &amp; Gales, 2021</a>)</p></li>
</ul>
</section>
<section id="LLM-as-a-Judge-Scorers">
<h2>LLM-as-a-Judge Scorers<a class="headerlink" href="#LLM-as-a-Judge-Scorers" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Categorical LLM-as-a-Judge (<a class="reference external" href="https://arxiv.org/abs/2303.08896">Manakul et al., 2023</a>; <a class="reference external" href="https://arxiv.org/abs/2308.16175">Chen &amp; Mueller, 2023</a>; <a class="reference external" href="https://arxiv.org/pdf/2303.15621">Luo et al., 2023</a>)</p></li>
<li><p>Continuous LLM-as-a-Judge (<a class="reference external" href="https://arxiv.org/pdf/2306.13063">Xiong et al., 2024</a>)</p></li>
</ul>
</p></div><section id="📊-What-You'll-Do-in-This-Demo">
<h3>📊 What You’ll Do in This Demo<a class="headerlink" href="#📊-What-You'll-Do-in-This-Demo" title="Link to this heading">#</a></h3>
<div style="display: flex; margin-bottom: 15px; align-items: center"><div style="background-color: #34a853; color: white; border-radius: 50%; width: 30px; height: 30px; display: flex; justify-content: center; align-items: center; margin-right: 15px; flex-shrink: 0"><p>1</p>
</div><div><p style="margin: 0; font-weight: bold"><p>Set up LLM and prompts.</p>
</p><p style="margin: 0; color: rgba(95, 99, 104, 0.8)"><p>Set up LLM instance and load example data prompts.</p>
</p></div></div><div style="display: flex; margin-bottom: 15px; align-items: center"><div style="background-color: #34a853; color: white; border-radius: 50%; width: 30px; height: 30px; display: flex; justify-content: center; align-items: center; margin-right: 15px; flex-shrink: 0"><p>2</p>
</div><div><p style="margin: 0; font-weight: bold"><p>Tune Ensemble Weights</p>
</p><p style="margin: 0; color: rgba(95, 99, 104, 0.8)"><p>Tune the ensemble weights on a set of tuning prompts. You will execute a single UQEnsemble.tune() method that will generate responses, compute confidence scores, and optimize weights using a provided answer key corresponding to the provided questions.</p>
</p></div></div><div style="display: flex; margin-bottom: 15px; align-items: center"><div style="background-color: #34a853; color: white; border-radius: 50%; width: 30px; height: 30px; display: flex; justify-content: center; align-items: center; margin-right: 15px; flex-shrink: 0"><p>3</p>
</div><div><p style="margin: 0; font-weight: bold"><p>Generate LLM Responses and Confidence Scores with Tuned Ensemble.</p>
</p><p style="margin: 0; color: rgba(95, 99, 104, 0.8)"><p>Generate and score LLM responses to the example questions using the tuned UQEnsemble() object.</p>
</p></div></div><div style="display: flex; margin-bottom: 25px; align-items: center"><div style="background-color: #34a853; color: white; border-radius: 50%; width: 30px; height: 30px; display: flex; justify-content: center; align-items: center; margin-right: 15px; flex-shrink: 0"><p>4</p>
</div><div><p style="margin: 0; font-weight: bold"><p>Evaluate Hallucination Detection Performance.</p>
</p><p style="margin: 0; color: rgba(95, 99, 104, 0.8)"><p>Visualize LLM accuracy at different thresholds of the ensemble score that combines various scorers. Compute precision, recall, and F1-score of hallucination detection.</p>
</p></div></div></section>
<section id="⚖️-Advantages-&amp;-Limitations">
<h3>⚖️ Advantages &amp; Limitations<a class="headerlink" href="#⚖️-Advantages-&-Limitations" title="Link to this heading">#</a></h3>
<div style="display: flex; gap: 20px"><div style="flex: 1; background-color: rgba(0, 200, 0, 0.1); padding: 15px; border-radius: 8px; border: 1px solid rgba(0, 200, 0, 0.2)"><h3 style="color: #2e8b57; margin-top: 0"><p>Pros</p>
</h3><ul style="margin-bottom: 0"><li><p>Highly Flexible: Versatile and adaptable to various tasks and question types.</p>
</li><li><p>Highly Customizable: Ensemble weights can be tuned for optimal performance on a specific use case.</p>
</li></ul></div><div style="flex: 1; background-color: rgba(200, 0, 0, 0.1); padding: 15px; border-radius: 8px; border: 1px solid rgba(200, 0, 0, 0.2)"><h3 style="color: #b22222; margin-top: 0"><p>Cons</p>
</h3><ul style="margin-bottom: 0"><li><p>Requires More Setup: Not quite “off-the-shelf”; requires some effort to configure and tune the ensemble.</p>
</li><li><p>Best for Advanced Users: Optimizing the ensemble requires a deeper understanding of the individual scorers.</p>
</li></ul></div></div><div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">precision_score</span><span class="p">,</span> <span class="n">recall_score</span><span class="p">,</span> <span class="n">f1_score</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">uqlm</span><span class="w"> </span><span class="kn">import</span> <span class="n">UQEnsemble</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">uqlm.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_example_dataset</span><span class="p">,</span> <span class="n">math_postprocessor</span><span class="p">,</span> <span class="n">plot_model_accuracies</span>
</pre></div>
</div>
</div>
<p>## 1. Set up LLM and Prompts</p>
<p>In this demo, we will illustrate this approach using a set of math questions from the <a class="reference external" href="https://github.com/openai/grade-school-math">GSM8K benchmark</a>. To implement with your use case, simply <strong>replace the example prompts with your data</strong>.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Load example dataset (GSM8K)</span>
<span class="n">gsm8k</span> <span class="o">=</span> <span class="n">load_example_dataset</span><span class="p">(</span><span class="s2">&quot;gsm8k&quot;</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">gsm8k</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Loading dataset - gsm8k...
Processing dataset...
Dataset ready!
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>question</th>
      <th>answer</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Natalia sold clips to 48 of her friends in Apr...</td>
      <td>72</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Weng earns $12 an hour for babysitting. Yester...</td>
      <td>10</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Betty is saving money for a new wallet which c...</td>
      <td>5</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Julie is reading a 120-page book. Yesterday, s...</td>
      <td>42</td>
    </tr>
    <tr>
      <th>4</th>
      <td>James writes a 3-page letter to 2 different fr...</td>
      <td>624</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">gsm8k_tune</span> <span class="o">=</span> <span class="n">gsm8k</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">50</span><span class="p">]</span>
<span class="n">gsm8k_test</span> <span class="o">=</span> <span class="n">gsm8k</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">51</span><span class="p">:</span><span class="mi">100</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define prompts</span>
<span class="n">MATH_INSTRUCTION</span> <span class="o">=</span> <span class="s2">&quot;When you solve this math problem only return the answer with no additional text.</span><span class="se">\n</span><span class="s2">&quot;</span>
<span class="n">tune_prompts</span> <span class="o">=</span> <span class="p">[</span><span class="n">MATH_INSTRUCTION</span> <span class="o">+</span> <span class="n">prompt</span> <span class="k">for</span> <span class="n">prompt</span> <span class="ow">in</span> <span class="n">gsm8k_tune</span><span class="o">.</span><span class="n">question</span><span class="p">]</span>
<span class="n">test_prompts</span> <span class="o">=</span> <span class="p">[</span><span class="n">MATH_INSTRUCTION</span> <span class="o">+</span> <span class="n">prompt</span> <span class="k">for</span> <span class="n">prompt</span> <span class="ow">in</span> <span class="n">gsm8k_test</span><span class="o">.</span><span class="n">question</span><span class="p">]</span>
</pre></div>
</div>
</div>
<p>In this example, we use <code class="docutils literal notranslate"><span class="pre">ChatVertexAI</span></code> and <code class="docutils literal notranslate"><span class="pre">AzureChatOpenAI</span></code> to instantiate our LLMs, but any <a class="reference external" href="https://js.langchain.com/docs/integrations/chat/">LangChain Chat Model</a> may be used. Be sure to <strong>replace with your LLM of choice.</strong></p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># import sys</span>
<span class="c1"># !{sys.executable} -m pip install python-dotenv</span>
<span class="c1"># !{sys.executable} -m pip install langchain-openai</span>

<span class="c1"># # User to populate .env file with API credentials. In this step, replace with your LLM of choice.</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">dotenv</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dotenv</span><span class="p">,</span> <span class="n">find_dotenv</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">langchain_openai</span><span class="w"> </span><span class="kn">import</span> <span class="n">AzureChatOpenAI</span>

<span class="n">load_dotenv</span><span class="p">(</span><span class="n">find_dotenv</span><span class="p">())</span>
<span class="n">gpt</span> <span class="o">=</span> <span class="n">AzureChatOpenAI</span><span class="p">(</span>
    <span class="n">deployment_name</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">&quot;DEPLOYMENT_NAME&quot;</span><span class="p">),</span>
    <span class="n">openai_api_key</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">&quot;API_KEY&quot;</span><span class="p">),</span>
    <span class="n">azure_endpoint</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">&quot;API_BASE&quot;</span><span class="p">),</span>
    <span class="n">openai_api_type</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">&quot;API_TYPE&quot;</span><span class="p">),</span>
    <span class="n">openai_api_version</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">&quot;API_VERSION&quot;</span><span class="p">),</span>
    <span class="n">temperature</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>  <span class="c1"># User to set temperature</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># import sys</span>
<span class="c1"># !{sys.executable} -m pip install langchain-google-vertexai</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">langchain_google_vertexai</span><span class="w"> </span><span class="kn">import</span> <span class="n">ChatVertexAI</span>

<span class="n">gemini</span> <span class="o">=</span> <span class="n">ChatVertexAI</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s2">&quot;gemini-1.5-flash&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>## 2. Tune Ensemble</p>
<section id="UQEnsemble()---Ensemble-of-uncertainty-scorers">
<h4><code class="docutils literal notranslate"><span class="pre">UQEnsemble()</span></code> - Ensemble of uncertainty scorers<a class="headerlink" href="#UQEnsemble()---Ensemble-of-uncertainty-scorers" title="Link to this heading">#</a></h4>
</section>
</section>
</section>
<section id="📋-Class-Attributes">
<h2>📋 Class Attributes<a class="headerlink" href="#📋-Class-Attributes" title="Link to this heading">#</a></h2>
<table style="border-collapse: collapse; width: 100%; border: 1px solid rgba(127, 127, 127, 0.2);"><tr><th style="background-color: rgba(200, 200, 200, 0.2); width: 20%; padding: 8px; text-align: left; border: 1px solid rgba(127, 127, 127, 0.2);"><p>Parameter</p>
</th><th style="background-color: rgba(200, 200, 200, 0.2); width: 25%; padding: 8px; text-align: left; border: 1px solid rgba(127, 127, 127, 0.2);"><p>Type &amp; Default</p>
</th><th style="background-color: rgba(200, 200, 200, 0.2); width: 55%; padding: 8px; text-align: left; border: 1px solid rgba(127, 127, 127, 0.2);"><p>Description</p>
</th></tr><tr><td style="font-weight: bold; padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>llm</p>
</td><td style="padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>BaseChatModeldefault=None</p>
</td><td style="padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>A langchain llm <code class="docutils literal notranslate"><span class="pre">BaseChatModel</span></code>. User is responsible for specifying temperature and other relevant parameters to the constructor of the provided <code class="docutils literal notranslate"><span class="pre">llm</span></code> object.</p>
</td></tr><tr><td style="font-weight: bold; padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>scorers</p>
</td><td style="padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>Listdefault=None</p>
</td><td style="padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>Specifies which black-box, white-box, or LLM-as-a-Judge scorers to include in the ensemble. List containing instances of BaseChatModel, LLMJudge, black-box scorer names from [‘semantic_negentropy’, ‘noncontradiction’,’exact_match’, ‘bert_score’, ‘bleurt’, ‘cosine_sim’], or white-box scorer names from [“normalized_probability”, “min_probability”]. If None, defaults to the off-the-shelf BS Detector ensemble by Chen &amp; Mueller, 2023 which uses components [“noncontradiction”,
“exact_match”,”self_reflection”] with respective weights of [0.56, 0.14, 0.3].</p>
</td></tr><tr><td style="font-weight: bold; padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>device</p>
</td><td style="padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>str or torch.devicedefault=”cpu”</p>
</td><td style="padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>Specifies the device that NLI model use for prediction. Only applies to ‘semantic_negentropy’, ‘noncontradiction’ scorers. Pass a torch.device to leverage GPU.</p>
</td></tr><tr><td style="font-weight: bold; padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>use_best</p>
</td><td style="padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>booldefault=True</p>
</td><td style="padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>Specifies whether to swap the original response for the uncertainty-minimized response among all sampled responses based on semantic entropy clusters. Only used if <code class="docutils literal notranslate"><span class="pre">scorers</span></code> includes ‘semantic_negentropy’ or ‘noncontradiction’.</p>
</td></tr><tr><td style="font-weight: bold; padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>system_prompt</p>
</td><td style="padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>str or Nonedefault=”You are a helpful assistant.”</p>
</td><td style="padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>Optional argument for user to provide custom system prompt for the LLM.</p>
</td></tr><tr><td style="font-weight: bold; padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>max_calls_per_min</p>
</td><td style="padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>intdefault=None</p>
</td><td style="padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>Specifies how many API calls to make per minute to avoid rate limit errors. By default, no limit is specified.</p>
</td></tr><tr><td style="font-weight: bold; padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>use_n_param</p>
</td><td style="padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>booldefault=False</p>
</td><td style="padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>Specifies whether to use n parameter for BaseChatModel. Not compatible with all BaseChatModel classes. If used, it speeds up the generation process substantially when num_responses is large.</p>
</td></tr><tr><td style="font-weight: bold; padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>postprocessor</p>
</td><td style="padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>callabledefault=None</p>
</td><td style="padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>A user-defined function that takes a string input and returns a string. Used for postprocessing outputs.</p>
</td></tr><tr><td style="font-weight: bold; padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>sampling_temperature</p>
</td><td style="padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>floatdefault=1</p>
</td><td style="padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>The ‘temperature’ parameter for LLM model to generate sampled LLM responses. Must be greater than 0.</p>
</td></tr><tr><td style="font-weight: bold; padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>weights</p>
</td><td style="padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>list of floatsdefault=None</p>
</td><td style="padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>Specifies weight for each component in ensemble. If None, and scorers is not None, and defaults to equal weights for each scorer. These weights get updated with tune method is executed.</p>
</td></tr><tr><td style="font-weight: bold; padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>nli_model_name</p>
</td><td style="padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>strdefault=”microsoft/deberta-large-mnli”</p>
</td><td style="padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>Specifies which NLI model to use. Must be acceptable input to AutoTokenizer.from_pretrained() and AutoModelForSequenceClassification.from_pretrained().</p>
</td></tr></table></section>
<section id="🔍-Parameter-Groups">
<h2>🔍 Parameter Groups<a class="headerlink" href="#🔍-Parameter-Groups" title="Link to this heading">#</a></h2>
<div style="display: flex; gap: 20px; margin-bottom: 20px"><div style="flex: 1; padding: 10px; background-color: rgba(0, 100, 200, 0.1); border-radius: 5px; border: 1px solid rgba(0, 100, 200, 0.2);"><p style="font-weight: bold"><p>🧠 LLM-Specific</p>
</p><ul><li><p>llm</p>
</li><li><p>system_prompt</p>
</li><li><p>sampling_temperature</p>
</li></ul></div><div style="flex: 1; padding: 10px; background-color: rgba(0, 200, 0, 0.1); border-radius: 5px; border: 1px solid rgba(0, 200, 0, 0.2);"><p style="font-weight: bold"><p>📊 Confidence Scores</p>
</p><ul><li><p>scorers</p>
</li><li><p>weights</p>
</li><li><p>use_best</p>
</li><li><p>nli_model_name</p>
</li><li><p>postprocessor</p>
</li></ul></div><div style="flex: 1; padding: 10px; background-color: rgba(200, 150, 0, 0.1); border-radius: 5px; border: 1px solid rgba(200, 150, 0, 0.2);"><p style="font-weight: bold"><p>🖥️ Hardware</p>
</p><ul><li><p>device</p>
</li></ul></div><div style="flex: 1; padding: 10px; background-color: rgba(200, 0, 200, 0.1); border-radius: 5px; border: 1px solid rgba(200, 0, 200, 0.2);"><p style="font-weight: bold"><p>⚡ Performance</p>
</p><ul><li><p>max_calls_per_min</p>
</li><li><p>use_n_param</p>
</li></ul></div></div></section>
<section id="💻-Usage-Examples">
<h2>💻 Usage Examples<a class="headerlink" href="#💻-Usage-Examples" title="Link to this heading">#</a></h2>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Basic usage with default parameters</span>
<span class="n">uqe</span> <span class="o">=</span> <span class="n">UQEnsemble</span><span class="p">(</span><span class="n">llm</span><span class="o">=</span><span class="n">llm</span><span class="p">)</span>

<span class="c1"># Using GPU acceleration</span>
<span class="n">uqe</span> <span class="o">=</span> <span class="n">UQEnsemble</span><span class="p">(</span><span class="n">llm</span><span class="o">=</span><span class="n">llm</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">))</span>

<span class="c1"># Custom scorer list</span>
<span class="n">uqe</span> <span class="o">=</span> <span class="n">BlackBoxUQ</span><span class="p">(</span><span class="n">llm</span><span class="o">=</span><span class="n">llm</span><span class="p">,</span> <span class="n">scorers</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;bert_score&quot;</span><span class="p">,</span> <span class="s2">&quot;exact_match&quot;</span><span class="p">,</span> <span class="n">llm</span><span class="p">])</span>

<span class="c1"># High-throughput configuration with rate limiting</span>
<span class="n">uqe</span> <span class="o">=</span> <span class="n">UQEnsemble</span><span class="p">(</span><span class="n">llm</span><span class="o">=</span><span class="n">llm</span><span class="p">,</span> <span class="n">max_calls_per_min</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">use_n_param</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>

<span class="c1"># Set the torch device</span>
<span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>  <span class="c1"># NVIDIA GPU</span>
    <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>
<span class="k">elif</span> <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">mps</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>  <span class="c1"># macOS</span>
    <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;mps&quot;</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>  <span class="c1"># CPU</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Using </span><span class="si">{</span><span class="n">device</span><span class="o">.</span><span class="n">type</span><span class="si">}</span><span class="s2"> device&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Using cuda device
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">scorers</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;exact_match&quot;</span><span class="p">,</span>  <span class="c1"># Measures proportion of candidate responses that match original response (black-box)</span>
    <span class="s2">&quot;noncontradiction&quot;</span><span class="p">,</span>  <span class="c1"># mean non-contradiction probability between candidate responses and original response (black-box)</span>
    <span class="s2">&quot;normalized_probability&quot;</span><span class="p">,</span>  <span class="c1"># length-normalized joint token probability (white-box)</span>
    <span class="n">gpt</span><span class="p">,</span>  <span class="c1"># LLM-as-a-judge (self)</span>
    <span class="n">gemini</span><span class="p">,</span>  <span class="c1"># LLM-as-a-judge (separate LLM)</span>
<span class="p">]</span>

<span class="n">uqe</span> <span class="o">=</span> <span class="n">UQEnsemble</span><span class="p">(</span>
    <span class="n">llm</span><span class="o">=</span><span class="n">gpt</span><span class="p">,</span>
    <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span>
    <span class="n">max_calls_per_min</span><span class="o">=</span><span class="mi">175</span><span class="p">,</span>
    <span class="c1"># postprocessor=math_postprocessor,</span>
    <span class="n">use_n_param</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>  <span class="c1"># Set True if using AzureChatOpenAI for faster generation</span>
    <span class="n">scorers</span><span class="o">=</span><span class="n">scorers</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Some weights of the model checkpoint at microsoft/deberta-large-mnli were not used when initializing DebertaForSequenceClassification: [&#39;config&#39;]
- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
</pre></div></div>
</div>
<p><img alt="Sample Image" src="https://raw.githubusercontent.com/cvs-health/uqlm/develop/assets/images/uqensemble_generate_score.png" /></p>
<table style="border-collapse: collapse; width: 100%; border: 1px solid rgba(127, 127, 127, 0.2);"><tr><th style="background-color: rgba(200, 200, 200, 0.2); width: 25%; padding: 8px; text-align: left; border: 1px solid rgba(127, 127, 127, 0.2);"><p>Method</p>
</th><th style="background-color: rgba(200, 200, 200, 0.2); width: 75%; padding: 8px; text-align: left; border: 1px solid rgba(127, 127, 127, 0.2);"><p>Description &amp; Parameters</p>
</th></tr><tr><td style="font-weight: bold; vertical-align: top; padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>UQEnsemble.tune</p>
</td><td style="padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p><p>Generate responses from provided prompts, grade responses with provided grader function, and tune ensemble weights. If weights and threshold objectives match, joint optimization will happen. Otherwise, sequential optimization will happen. If an optimization problem has fewer than three choice variables, grid search will happen.</p>
</p><p><p>Parameters:</p>
</p><ul><li><p>prompts - (list of str) A list of input prompts for the model.</p>
</li><li><p>ground_truth_answers - (List[str]) A list of ideal (correct) responses.</p>
</li><li><p>grader_function - (callable, default=None) A user-defined function that takes a response and a ground truth ‘answer’ and returns a boolean indicator of whether the response is correct. If not provided, vectara’s HHEM is used: <a class="reference external" href="https://huggingface.co/vectara/hallucination_evaluation_model">https://huggingface.co/vectara/hallucination_evaluation_model</a></p>
</li><li><p>num_responses - (int, default=5) The number of sampled responses used to compute consistency.</p>
</li><li><p>weights_objective - (str, default=’roc_auc’) Objective function for weight optimization. One of {‘fbeta_score’, ‘accuracy_score’, ‘balanced_accuracy_score’, ‘roc_auc’, ‘log_loss’, ‘average_precision’, ‘brier_score’}. Must match thresh_objective if one of {‘fbeta_score’, ‘accuracy_score’, ‘balanced_accuracy_score’}. If same as thresh_objective, joint optimization will be done.</p>
</li><li><p>thresh_objective - (str, default=’fbeta_score’) Objective function for threshold optimization via grid search. One of {‘fbeta_score’, ‘accuracy_score’, ‘balanced_accuracy_score’}.</p>
</li><li><p>thresh_bounds - (tuple of floats, default=(0,1)) Bounds to search for threshold.</p>
</li><li><p>n_trials - (int, default=100) Indicates how many trials to search over with optuna optimizer</p>
</li><li><p>step_size - (float, default=0.01) Indicates step size in grid search, if used.</p>
</li><li><p>fscore_beta - (float, default=1) Value of beta in fbeta_score.</p>
</li></ul><p><p>Returns: UQResult containing data (prompts, responses, sampled responses, and confidence scores) and metadata</p>
</p><div style="background-color: rgba(0, 200, 0, 0.1); padding: 8px; border-radius: 3px; margin-top: 10px; border: 1px solid rgba(0, 200, 0, 0.2); margin-right: 5px; box-sizing: border-box; width: 100%;"><p>💡 Best For: Tuning an optimized ensemble for detecting hallucinations in a specific use case.</p>
</div></td></tr></table><p>Note that below, we are providing a grader function that is specific to our use case (math questions). If you are running this example notebook with your own prompts/questions, update the grader function accordingly. Note that the default grader function, <code class="docutils literal notranslate"><span class="pre">vectara/hallucination_evaluation_model</span></code>, is used if no grader function is provided and generally works well across use cases.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">grade_response</span><span class="p">(</span><span class="n">response</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">answer</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">math_postprocessor</span><span class="p">(</span><span class="n">response</span><span class="p">)</span> <span class="o">==</span> <span class="n">answer</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tune_results</span> <span class="o">=</span> <span class="k">await</span> <span class="n">uqe</span><span class="o">.</span><span class="n">tune</span><span class="p">(</span>
    <span class="n">prompts</span><span class="o">=</span><span class="n">tune_prompts</span><span class="p">,</span>  <span class="c1"># prompts for tuning (responses will be generated from these prompts)</span>
    <span class="n">ground_truth_answers</span><span class="o">=</span><span class="n">gsm8k_tune</span><span class="p">[</span><span class="s2">&quot;answer&quot;</span><span class="p">],</span>  <span class="c1"># correct answers to &#39;grade&#39; LLM responses against</span>
    <span class="n">grader_function</span><span class="o">=</span><span class="n">grade_response</span><span class="p">,</span>  <span class="c1"># grader function to grade responses against provided answers</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Generating responses...
Generating candidate responses...
Computing confidence scores...
Generating LLMJudge scores...
Generating LLMJudge scores...
Grading responses with grader function...
Optimizing weights...
Optimizing threshold with grid search...
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">result_df</span> <span class="o">=</span> <span class="n">tune_results</span><span class="o">.</span><span class="n">to_df</span><span class="p">()</span>
<span class="n">result_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>prompt</th>
      <th>response</th>
      <th>sampled_responses</th>
      <th>ensemble_score</th>
      <th>exact_match</th>
      <th>noncontradiction</th>
      <th>normalized_probability</th>
      <th>judge_1</th>
      <th>judge_2</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>When you solve this math problem only return t...</td>
      <td>72</td>
      <td>[72, 72, 72, 72, 72]</td>
      <td>0.952566</td>
      <td>1.0</td>
      <td>1.000000</td>
      <td>0.999188</td>
      <td>1.0</td>
      <td>0.5</td>
    </tr>
    <tr>
      <th>1</th>
      <td>When you solve this math problem only return t...</td>
      <td>$10</td>
      <td>[$10, $10, $10, $10, $10]</td>
      <td>0.895037</td>
      <td>1.0</td>
      <td>1.000000</td>
      <td>0.999019</td>
      <td>0.0</td>
      <td>0.5</td>
    </tr>
    <tr>
      <th>2</th>
      <td>When you solve this math problem only return t...</td>
      <td>$20</td>
      <td>[$20, $20, $20, $20, $10]</td>
      <td>0.762877</td>
      <td>0.8</td>
      <td>0.801301</td>
      <td>0.946584</td>
      <td>1.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>When you solve this math problem only return t...</td>
      <td>48</td>
      <td>[48, 48, 48, 48, 48]</td>
      <td>0.941798</td>
      <td>1.0</td>
      <td>1.000000</td>
      <td>0.996091</td>
      <td>0.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>When you solve this math problem only return t...</td>
      <td>624</td>
      <td>[624, 624, 624, 624, 624]</td>
      <td>0.999969</td>
      <td>1.0</td>
      <td>1.000000</td>
      <td>0.999828</td>
      <td>1.0</td>
      <td>1.0</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">weight</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">uqe</span><span class="o">.</span><span class="n">weights</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Weight for </span><span class="si">{</span><span class="n">uqe</span><span class="o">.</span><span class="n">component_names</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">weight</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Weight for exact_match: 0.14848838407926002
Weight for noncontradiction: 0.5195905565435162
Weight for normalized_probability: 0.17984565170407496
Weight for judge_1: 0.05749867602904491
Weight for judge_2: 0.09457673164410399
</pre></div></div>
</div>
<p>## 3. Generate LLM Responses and Confidence Scores</p>
<p>To evaluate hallucination detection performance, we will generate responses and corresponding confidence scores on a holdout set using the tuned ensemble.</p>
<p><img alt="Sample Image" src="https://raw.githubusercontent.com/cvs-health/uqlm/develop/assets/images/uqensemble_generate_score.png" /></p>
<table style="border-collapse: collapse; width: 100%; border: 1px solid rgba(127, 127, 127, 0.2);"><tr><th style="background-color: rgba(200, 200, 200, 0.2); width: 25%; padding: 8px; text-align: left; border: 1px solid rgba(127, 127, 127, 0.2);"><p>Method</p>
</th><th style="background-color: rgba(200, 200, 200, 0.2); width: 75%; padding: 8px; text-align: left; border: 1px solid rgba(127, 127, 127, 0.2);"><p>Description &amp; Parameters</p>
</th></tr><tr><td style="font-weight: bold; vertical-align: top; padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>UQEnsemble.generate_and_score</p>
</td><td style="padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p><p>Generate LLM responses, sampled LLM (candidate) responses, and compute confidence scores for the provided prompts.</p>
</p><p><p>Parameters:</p>
</p><ul><li><p>prompts - (list of str) A list of input prompts for the model.</p>
</li><li><p>num_responses - (int, default=5) The number of sampled responses used to compute consistency.</p>
</li></ul><p><p>Returns: UQResult containing data (prompts, responses, sampled responses, and confidence scores) and metadata</p>
</p><div style="background-color: rgba(0, 200, 0, 0.1); padding: 8px; border-radius: 3px; margin-top: 10px; border: 1px solid rgba(0, 200, 0, 0.2); margin-right: 5px; box-sizing: border-box; width: 100%;"><p>💡 Best For: Complete end-to-end uncertainty quantification when starting with prompts.</p>
</div></td></tr><tr><td style="font-weight: bold; vertical-align: top; padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p>UQEnsemble.score</p>
</td><td style="padding: 8px; border: 1px solid rgba(127, 127, 127, 0.2);"><p><p>Compute confidence scores on provided LLM responses. Should only be used if responses and sampled responses are already generated.</p>
</p><p><p>Parameters:</p>
</p><ul><li><p>prompts - (list of str) A list of input prompts for the LLM.</p>
</li><li><p>responses - (list of str) A list of LLM responses for the prompts.</p>
</li><li><p>sampled_responses - (list of list of str, default=None) A list of lists of sampled LLM responses for each prompt. These will be used to compute consistency scores by comparing to the corresponding response from responses. Must be provided if using Black-Box scorers.</p>
</li><li><p>logprobs_results - (list of logprobs_result, default=None) List of lists of dictionaries, each returned by BaseChatModel.agenerate. Must be provided if using white box scorers.</p>
</li></ul><p><p>Returns: UQResult containing data (responses, sampled responses, and confidence scores) and metadata</p>
</p><div style="background-color: rgba(0, 200, 0, 0.1); padding: 8px; border-radius: 3px; margin-top: 10px; border: 1px solid rgba(0, 200, 0, 0.2); margin-right: 5px; box-sizing: border-box; width: 100%;"><p>💡 Best For: Computing uncertainty scores when responses are already generated elsewhere.</p>
</div></td></tr></table><div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">test_results</span> <span class="o">=</span> <span class="k">await</span> <span class="n">uqe</span><span class="o">.</span><span class="n">generate_and_score</span><span class="p">(</span><span class="n">prompts</span><span class="o">=</span><span class="n">test_prompts</span><span class="p">,</span> <span class="n">num_responses</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Generating responses...
Generating candidate responses...
Computing confidence scores...
Generating LLMJudge scores...
Generating LLMJudge scores...
</pre></div></div>
</div>
<p>## 4. Evaluate Hallucination Detection Performance</p>
<p>To evaluate hallucination detection performance, we ‘grade’ the responses against an answer key. Again, note that the <code class="docutils literal notranslate"><span class="pre">grade_response</span></code> function is specific to our use case (math questions). <strong>If you are using your own prompts/questions, update the grading method accordingly</strong>.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">test_result_df</span> <span class="o">=</span> <span class="n">test_results</span><span class="o">.</span><span class="n">to_df</span><span class="p">()</span>
<span class="n">test_result_df</span><span class="p">[</span><span class="s2">&quot;response_correct&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">grade_response</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">a</span><span class="p">)</span> <span class="k">for</span> <span class="n">r</span><span class="p">,</span> <span class="n">a</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">test_result_df</span><span class="p">[</span><span class="s2">&quot;response&quot;</span><span class="p">],</span> <span class="n">gsm8k_test</span><span class="p">[</span><span class="s2">&quot;answer&quot;</span><span class="p">])]</span>
<span class="n">test_result_df</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>prompt</th>
      <th>response</th>
      <th>sampled_responses</th>
      <th>ensemble_score</th>
      <th>exact_match</th>
      <th>noncontradiction</th>
      <th>normalized_probability</th>
      <th>judge_1</th>
      <th>judge_2</th>
      <th>response_correct</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>When you solve this math problem only return t...</td>
      <td>160</td>
      <td>[68, 176, 152, 80, 72]</td>
      <td>0.030060</td>
      <td>0.0</td>
      <td>0.021150</td>
      <td>0.106042</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>True</td>
    </tr>
    <tr>
      <th>1</th>
      <td>When you solve this math problem only return t...</td>
      <td>12</td>
      <td>[12, 14, 18, 11, 13]</td>
      <td>0.158690</td>
      <td>0.2</td>
      <td>0.240650</td>
      <td>0.021982</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>False</td>
    </tr>
    <tr>
      <th>2</th>
      <td>When you solve this math problem only return t...</td>
      <td>$36</td>
      <td>[$36, $36, $36, $36, 36]</td>
      <td>0.870801</td>
      <td>0.8</td>
      <td>0.994231</td>
      <td>0.989287</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>True</td>
    </tr>
    <tr>
      <th>3</th>
      <td>When you solve this math problem only return t...</td>
      <td>9</td>
      <td>[$3, $9, 3, $10, 9]</td>
      <td>0.359167</td>
      <td>0.2</td>
      <td>0.452459</td>
      <td>0.205047</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>False</td>
    </tr>
    <tr>
      <th>4</th>
      <td>When you solve this math problem only return t...</td>
      <td>75%</td>
      <td>[75%, 75., 75%, 75%, 75%]</td>
      <td>0.873314</td>
      <td>0.8</td>
      <td>0.998718</td>
      <td>0.990297</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>True</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;&quot;&quot;Baseline LLM accuracy: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">test_result_df</span><span class="p">[</span><span class="s2">&quot;response_correct&quot;</span><span class="p">])</span><span class="si">}</span><span class="s2">&quot;&quot;&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Baseline LLM accuracy: 0.5714285714285714
</pre></div></div>
</div>
</section>
<section id="4.1-Filtered-LLM-Accuracy-Evaluation">
<h2>4.1 Filtered LLM Accuracy Evaluation<a class="headerlink" href="#4.1-Filtered-LLM-Accuracy-Evaluation" title="Link to this heading">#</a></h2>
<p>Here, we explore ‘filtered accuracy’ as a metric for evaluating the performance of our confidence scores. Filtered accuracy measures the change in LLM performance when responses with confidence scores below a specified threshold are excluded. By adjusting the confidence score threshold, we can observe how the accuracy of the LLM improves as less certain responses are filtered out.</p>
<p>We will plot the filtered accuracy across various confidence score thresholds to visualize the relationship between confidence and LLM accuracy. This analysis helps in understanding the trade-off between response coverage (measured by sample size below) and LLM accuracy, providing insights into the reliability of the LLM’s outputs.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_model_accuracies</span><span class="p">(</span><span class="n">scores</span><span class="o">=</span><span class="n">test_result_df</span><span class="o">.</span><span class="n">ensemble_score</span><span class="p">,</span> <span class="n">correct_indicators</span><span class="o">=</span><span class="n">test_result_df</span><span class="o">.</span><span class="n">response_correct</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/_notebooks_examples_ensemble_tuning_demo_30_0.png" src="../../_images/_notebooks_examples_ensemble_tuning_demo_30_0.png" />
</div>
</div>
</section>
<section id="4.2-Precision,-Recall,-F1-Score-of-Hallucination-Detection">
<h2>4.2 Precision, Recall, F1-Score of Hallucination Detection<a class="headerlink" href="#4.2-Precision,-Recall,-F1-Score-of-Hallucination-Detection" title="Link to this heading">#</a></h2>
<p>Lastly, we compute the optimal threshold for binarizing confidence scores, using F1-score as the objective. Using this threshold, we compute precision, recall, and F1-score for black box scorer predictions of whether responses are correct.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[19]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># extract optimal threshold</span>
<span class="n">best_threshold</span> <span class="o">=</span> <span class="n">uqe</span><span class="o">.</span><span class="n">thresh</span>

<span class="c1"># Define score vector and corresponding correct indicators (i.e. ground truth)</span>
<span class="n">y_scores</span> <span class="o">=</span> <span class="n">test_result_df</span><span class="p">[</span><span class="s2">&quot;ensemble_score&quot;</span><span class="p">]</span>  <span class="c1"># confidence score</span>
<span class="n">correct_indicators</span> <span class="o">=</span> <span class="p">(</span><span class="n">test_result_df</span><span class="o">.</span><span class="n">response_correct</span><span class="p">)</span> <span class="o">*</span> <span class="mi">1</span>  <span class="c1"># Whether responses is actually correct</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="p">[(</span><span class="n">s</span> <span class="o">&gt;</span> <span class="n">best_threshold</span><span class="p">)</span> <span class="o">*</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">y_scores</span><span class="p">]</span>  <span class="c1"># predicts whether response is correct based on confidence score</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Ensemble F1-optimal threshold: </span><span class="si">{</span><span class="n">best_threshold</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Ensemble F1-optimal threshold: 0.36
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[20]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># evaluate precision, recall, and f1-score of semantic entropy predictions of correctness</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Ensemble precision: </span><span class="si">{</span><span class="n">precision_score</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">correct_indicators</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred</span><span class="o">=</span><span class="n">y_pred</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Ensemble recall: </span><span class="si">{</span><span class="n">recall_score</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">correct_indicators</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred</span><span class="o">=</span><span class="n">y_pred</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Ensemble f1-score: </span><span class="si">{</span><span class="n">f1_score</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">correct_indicators</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred</span><span class="o">=</span><span class="n">y_pred</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Ensemble precision: 0.6585365853658537
Ensemble recall: 0.9642857142857143
Ensemble f1-score: 0.782608695652174
</pre></div></div>
</div>
<section id="5.-Scorer-Definitions">
<h3>5. Scorer Definitions<a class="headerlink" href="#5.-Scorer-Definitions" title="Link to this heading">#</a></h3>
<section id="Black-Box-Scorers">
<h4>Black-Box Scorers<a class="headerlink" href="#Black-Box-Scorers" title="Link to this heading">#</a></h4>
<p>Black-Box UQ scorers exploit variation in LLM responses to the same prompt to measure semantic consistency. All scorers have outputs ranging from 0 to 1, with higher values indicating higher confidence.</p>
<p>For a given prompt <span class="math notranslate nohighlight">\(x_i\)</span>, these approaches involves generating <span class="math notranslate nohighlight">\(m\)</span> responses <span class="math notranslate nohighlight">\(\tilde{\mathbf{y}}_i = \{ \tilde{y}_{i1},...,\tilde{y}_{im}\}\)</span>, using a non-zero temperature, from the same prompt and comparing these responses to the original response <span class="math notranslate nohighlight">\(y_{i}\)</span>. We provide detailed descriptions of each below.</p>
</section>
</section>
</section>
<section id="Exact-Match-Rate-(exact_match)">
<h2>Exact Match Rate (<code class="docutils literal notranslate"><span class="pre">exact_match</span></code>)<a class="headerlink" href="#Exact-Match-Rate-(exact_match)" title="Link to this heading">#</a></h2>
<p>Exact Match Rate (EMR) computes the proportion of candidate responses that are identical to the original response.</p>
<div class="math notranslate nohighlight">
\[EMR(y_i; \tilde{\mathbf{y}}_i) = \frac{1}{m} \sum_{j=1}^m \mathbb{I}(y_i=\tilde{y}_{ij}).\]</div>
<p>For more on this scorer, refer to <a class="reference external" href="https://arxiv.org/abs/2305.14613">Cole et al., 2023</a>.</p>
</section>
<section id="Non-Contradiction-Probability-(noncontradiction)">
<h2>Non-Contradiction Probability (<code class="docutils literal notranslate"><span class="pre">noncontradiction</span></code>)<a class="headerlink" href="#Non-Contradiction-Probability-(noncontradiction)" title="Link to this heading">#</a></h2>
<p>Non-contradiction probability (NCP) computes the mean non-contradiction probability estimated by a natural language inference (NLI) model. This score is formally defined as follows:</p>
<dl class="simple">
<dt>:nbsphinx-math:<a href="#id1"><span class="problematic" id="id2">`</span></a>begin{equation}</dt><dd><p>NCP(y_i; tilde{mathbf{y}}_i) = frac{1}{m} sum_{j=1}^m(1 - p_j)</p>
</dd>
</dl>
<p>end{equation}` where</p>
<dl class="simple">
<dt>:nbsphinx-math:<a href="#id3"><span class="problematic" id="id4">`</span></a>begin{equation}</dt><dd><p>p_j = frac{eta(y_{i}, tilde{y}_{ij}) + eta(tilde{y}_{ij},y_i)}{2}.</p>
</dd>
</dl>
<p>end{equation}`</p>
<p>Above, <span class="math notranslate nohighlight">\(\eta(\tilde{y}_{ij},y_i)\)</span> denotes the contradiction probability estimated by the NLI model for response <span class="math notranslate nohighlight">\(y_i\)</span> and candidate <span class="math notranslate nohighlight">\(\tilde{y}_{ij}\)</span>. For more on this scorer, refer to <a class="reference external" href="https://arxiv.org/abs/2308.16175">Chen &amp; Mueller, 2023</a>, <a class="reference external" href="https://arxiv.org/abs/2305.19187">Lin et al., 2025</a>, or <a class="reference external" href="https://arxiv.org/abs/2303.08896">Manakul et al., 2023</a>.</p>
</section>
<section id="Normalized-Semantic-Negentropy-(semantic_negentropy)">
<h2>Normalized Semantic Negentropy (<code class="docutils literal notranslate"><span class="pre">semantic_negentropy</span></code>)<a class="headerlink" href="#Normalized-Semantic-Negentropy-(semantic_negentropy)" title="Link to this heading">#</a></h2>
<p>Normalized Semantic Negentropy (NSN) normalizes the standard computation of discrete semantic entropy to be increasing with higher confidence and have [0,1] support. In contrast to the EMR and NCP, semantic entropy does not distinguish between an original response and candidate responses. Instead, this approach computes a single metric value on a list of responses generated from the same prompt. Under this approach, responses are clustered using an NLI model based on mutual entailment. We
consider the discrete version of SE, where the final set of clusters is defined as follows:</p>
<dl class="simple">
<dt>:nbsphinx-math:<a href="#id5"><span class="problematic" id="id6">`</span></a>begin{equation}</dt><dd><p>SE(y_i; tilde{mathbf{y}}_i) = - sum_{C in mathcal{C}} P(C|y_i, tilde{mathbf{y}}_i)log P(C|y_i, tilde{mathbf{y}}_i),</p>
</dd>
</dl>
<p>end{equation}` where <span class="math notranslate nohighlight">\(P(C|y_i, \tilde{\mathbf{y}}_i)\)</span> denotes the probability a randomly selected response $y <span class="math">\in `{y_i} :nbsphinx-math:</span>cup <cite>:nbsphinx-math:</cite>tilde{mathbf{y}}`_i $ belongs to cluster <span class="math notranslate nohighlight">\(C\)</span>, and <span class="math notranslate nohighlight">\(\mathcal{C}\)</span> denotes the full set of clusters of <span class="math notranslate nohighlight">\(\{y_i\} \cup \tilde{\mathbf{y}}_i\)</span>.</p>
<dl class="simple">
<dt>To ensure that we have a normalized confidence score with <span class="math notranslate nohighlight">\([0,1]\)</span> support and with higher values corresponding to higher confidence, we implement the following normalization to arrive at <em>Normalized Semantic Negentropy</em> (NSN): :nbsphinx-math:<a href="#id7"><span class="problematic" id="id8">`</span></a>begin{equation}</dt><dd><p>NSN(y_i; tilde{mathbf{y}}_i) = 1 - frac{SE(y_i; tilde{mathbf{y}}_i)}{log m},</p>
</dd>
</dl>
<p>end{equation}` where <span class="math notranslate nohighlight">\(\log m\)</span> is included to normalize the support.</p>
</section>
<section id="BERTScore-(bert_score)">
<h2>BERTScore (<code class="docutils literal notranslate"><span class="pre">bert_score</span></code>)<a class="headerlink" href="#BERTScore-(bert_score)" title="Link to this heading">#</a></h2>
<p>Let a tokenized text sequence be denoted as <span class="math notranslate nohighlight">\(\textbf{t} = \{t_1,...t_L\}\)</span> and the corresponding contextualized word embeddings as <span class="math notranslate nohighlight">\(\textbf{E} = \{\textbf{e}_1,...,\textbf{e}_L\}\)</span>, where <span class="math notranslate nohighlight">\(L\)</span> is the number of tokens in the text. The BERTScore precision, recall, and F1-scores between two tokenized texts <span class="math notranslate nohighlight">\(\textbf{t}, \textbf{t}'\)</span> are respectively defined as follows:</p>
<dl class="simple">
<dt>:nbsphinx-math:<a href="#id9"><span class="problematic" id="id10">`</span></a>begin{equation}</dt><dd><p>BertP(textbf{t}, textbf{t}’) = frac{1}{| textbf{t}|} sum_{t in textbf{t}} max_{t’ in textbf{t}’} textbf{e} cdot textbf{e}’</p>
</dd>
</dl>
<p>end{equation}`</p>
<dl class="simple">
<dt>:nbsphinx-math:<a href="#id11"><span class="problematic" id="id12">`</span></a>begin{equation}</dt><dd><p>BertR(textbf{t}, textbf{t}’) = frac{1}{| textbf{t}’<a href="#id13"><span class="problematic" id="id14">|</span></a>} sum_{t’ in textbf{t}’} max_{t in textbf{t}} textbf{e} cdot textbf{e}’</p>
</dd>
</dl>
<p>end{equation}`</p>
<dl class="simple">
<dt>:nbsphinx-math:<a href="#id15"><span class="problematic" id="id16">`</span></a>begin{equation}</dt><dd><p>BertF(textbf{t}, textbf{t}’) = 2frac{ BertP(textbf{t}, textbf{t}’)  BertR(textbf{t}, textbf{t}’)}{BertPr(textbf{t}, textbf{t}’)  + BertRec(textbf{t}, textbf{t}’)},</p>
</dd>
<dt>end{equation}` where <span class="math notranslate nohighlight">\(e, e'\)</span> respectively correspond to <span class="math notranslate nohighlight">\(t, t'\)</span>. We compute our BERTScore-based confidence scores as follows: :nbsphinx-math:<a href="#id17"><span class="problematic" id="id18">`</span></a>begin{equation}</dt><dd><p>BertConfidence(y_i; tilde{mathbf{y}}_i) = frac{1}{m} sum_{j=1}^m BertF(y_i, tilde{y}_{ij}),</p>
</dd>
</dl>
<p>end{equation}` i.e. the average BERTScore F1 across pairings of the original response with all candidate responses. For more on BERTScore, refer to <a class="reference external" href="https://arxiv.org/abs/1904.09675">Zheng et al., 2020</a>.</p>
</section>
<section id="BLEURT-(bleurt)">
<h2>BLEURT (<code class="docutils literal notranslate"><span class="pre">bleurt</span></code>)<a class="headerlink" href="#BLEURT-(bleurt)" title="Link to this heading">#</a></h2>
<p>In contrast to the aforementioned scorers, BLEURT is specifically pre-trained and fine-tuned to learn human judgments of text similarity. Our BLEURT confidence score is the average BLEURT value across pairings of the original response with all candidate responses:</p>
<dl class="simple">
<dt>:nbsphinx-math:<a href="#id19"><span class="problematic" id="id20">`</span></a>begin{equation}</dt><dd><p>BLEURTConfidence(y_i; tilde{mathbf{y}}_i) = frac{1}{m} sum_{j=1}^m BLEURT(y_i, tilde{y}_{ij}).</p>
</dd>
</dl>
<p>end{equation}`</p>
<p>For more on this scorer, refer to <a class="reference external" href="https://arxiv.org/abs/2004.04696">Sellam et al., 2020</a>.</p>
</section>
<section id="Normalized-Cosine-Similarity-(cosine_sim)">
<h2>Normalized Cosine Similarity (<code class="docutils literal notranslate"><span class="pre">cosine_sim</span></code>)<a class="headerlink" href="#Normalized-Cosine-Similarity-(cosine_sim)" title="Link to this heading">#</a></h2>
<p>This scorer leverages a sentence transformer to map LLM outputs to an embedding space and measure similarity using those sentence embeddings. Let <span class="math notranslate nohighlight">\(V: \mathcal{Y} \xrightarrow{} \mathbb{R}^d\)</span> denote the sentence transformer, where <span class="math notranslate nohighlight">\(d\)</span> is the dimension of the embedding space. The average cosine similarity across pairings of the original response with all candidate responses is given as follows:</p>
<dl class="simple">
<dt>:nbsphinx-math:<a href="#id21"><span class="problematic" id="id22">`</span></a>begin{equation}</dt><dd><p>CS(y_i; tilde{mathbf{y}}_i) = frac{1}{m} sum_{i=1}^m   frac{mathbf{V}(y_i) cdot mathbf{V}(tilde{y}_{ij}) }{ lVert mathbf{V}(y_i) rVert lVert mathbf{V}(tilde{y}_{ij}) rVert}.</p>
</dd>
</dl>
<p>end{equation}`</p>
<p>To ensure a standardized support of <span class="math notranslate nohighlight">\([0, 1]\)</span>, we normalize cosine similarity to obtain confidence scores as follows:</p>
<dl class="simple">
<dt>:nbsphinx-math:<a href="#id23"><span class="problematic" id="id24">`</span></a>begin{equation}</dt><dd><p>NCS(y_i; tilde{mathbf{y}}_i) = frac{CS(y_i; tilde{mathbf{y}}_i) + 1}{2}.</p>
</dd>
</dl>
<p>end{equation}`</p>
<p>White-box UQ scorers leverage token probabilities of the LLM’s generated response to quantify uncertainty. All scorers have outputs ranging from 0 to 1, with higher values indicating higher confidence. We define two white-box UQ scorers below.</p>
</section>
<section id="Length-Normalized-Token-Probability-(normalized_probability)">
<h2>Length-Normalized Token Probability (<code class="docutils literal notranslate"><span class="pre">normalized_probability</span></code>)<a class="headerlink" href="#Length-Normalized-Token-Probability-(normalized_probability)" title="Link to this heading">#</a></h2>
<p>Let the tokenization LLM response <span class="math notranslate nohighlight">\(y_i\)</span> be denoted as <span class="math notranslate nohighlight">\(\{t_1,...,t_{L_i}\}\)</span>, where <span class="math notranslate nohighlight">\(L_i\)</span> denotes the number of tokens the response. Length-normalized token probability (LNTP) computes a length-normalized analog of joint token probability:</p>
<dl class="simple">
<dt>:nbsphinx-math:<a href="#id25"><span class="problematic" id="id26">`</span></a>begin{equation}</dt><dd><p>LNTP(y_i) = prod_{t in y_i}  p_t^{frac{1}{L_i}},</p>
</dd>
</dl>
<p>end{equation}` where <span class="math notranslate nohighlight">\(p_t\)</span> denotes the token probability for token <span class="math notranslate nohighlight">\(t\)</span>. Note that this score is equivalent to the geometric mean of token probabilities for response <span class="math notranslate nohighlight">\(y_i\)</span>. For more on this scorer, refer to <a class="reference external" href="https://arxiv.org/pdf/2002.07650">Malinin &amp; Gales, 2021</a>.</p>
</section>
<section id="Minimum-Token-Probability-(min_probability)">
<h2>Minimum Token Probability (<code class="docutils literal notranslate"><span class="pre">min_probability</span></code>)<a class="headerlink" href="#Minimum-Token-Probability-(min_probability)" title="Link to this heading">#</a></h2>
<p>Minimum token probability (MTP) uses the minimum among token probabilities for a given responses as a confidence score:</p>
<dl class="simple">
<dt>:nbsphinx-math:<a href="#id27"><span class="problematic" id="id28">`</span></a>begin{equation}</dt><dd><p>MTP(y_i) = min_{t in y_i}  p_t,</p>
</dd>
</dl>
<p>end{equation}` where <span class="math notranslate nohighlight">\(t\)</span> and <span class="math notranslate nohighlight">\(p_t\)</span> follow the same definitions as above. For more on this scorer, refer to <a class="reference external" href="https://arxiv.org/abs/2303.08896">Manakul et al., 2023</a>.</p>
<p>Under the LLM-as-a-Judge approach, either the same LLM that was used for generating the original responses or a different LLM is asked to form a judgment about a pre-generated response. Below, we define two LLM-as-a-Judge scorer templates. #### Categorical Judge Template (<code class="docutils literal notranslate"><span class="pre">true_false_uncertain</span></code>) We follow the approach proposed by <a class="reference external" href="https://arxiv.org/abs/2308.16175">Chen &amp; Mueller, 2023</a> in which an LLM is instructed to score a question-answer concatenation as either <em>incorrect</em>, <em>uncertain</em>,
or <em>correct</em> using a carefully constructed prompt. These categories are respectively mapped to numerical scores of 0, 0.5, and 1. We denote the LLM-as-a-judge scorers as <span class="math notranslate nohighlight">\(J: \mathcal{Y} \xrightarrow[]{} \{0, 0.5, 1\}\)</span>. Formally, we can write this scorer function as follows:</p>
<p>:nbsphinx-math:<a href="#id29"><span class="problematic" id="id30">`</span></a>begin{equation}
J(y_i) = begin{cases}</p>
<blockquote>
<div><p>0 &amp; text{LLM states response is incorrect} \
0.5 &amp; text{LLM states that it is uncertain} \
1 &amp; text{LLM states response is correct}.</p>
</div></blockquote>
<p>end{cases}
end{equation}`</p>
</section>
<section id="Continuous-Judge-Template-(continuous)">
<h2>Continuous Judge Template (<code class="docutils literal notranslate"><span class="pre">continuous</span></code>)<a class="headerlink" href="#Continuous-Judge-Template-(continuous)" title="Link to this heading">#</a></h2>
<p>For the continuous template, the LLM is asked to directly score a question-answer concatenation’s correctness on a scale of 0 to 1.</p>
<p>© 2025 CVS Health and/or one of its affiliates. All rights reserved.</p>
</section>
</section>


                </article>
              
              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="ensemble_off_the_shelf_demo.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">🎯 BS Detector: Off-the-Shelf Ensemble for LLM Uncertainty</p>
      </div>
    </a>
    <a class="right-next"
       href="judges_demo.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">🎯 LLM-as-a-Judge</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
<div
    id="pst-page-navigation-heading-2"
    class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc" aria-labelledby="pst-page-navigation-heading-2">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Black-Box-(Consistency)-Scorers">Black-Box (Consistency) Scorers</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#White-Box-(Token-Probability-Based)-Scorers">White-Box (Token-Probability-Based) Scorers</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#LLM-as-a-Judge-Scorers">LLM-as-a-Judge Scorers</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#📊-What-You'll-Do-in-This-Demo">📊 What You’ll Do in This Demo</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#⚖️-Advantages-&amp;-Limitations">⚖️ Advantages &amp; Limitations</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#UQEnsemble()---Ensemble-of-uncertainty-scorers"><code class="docutils literal notranslate"><span class="pre">UQEnsemble()</span></code> - Ensemble of uncertainty scorers</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#📋-Class-Attributes">📋 Class Attributes</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#🔍-Parameter-Groups">🔍 Parameter Groups</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#💻-Usage-Examples">💻 Usage Examples</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#4.1-Filtered-LLM-Accuracy-Evaluation">4.1 Filtered LLM Accuracy Evaluation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#4.2-Precision,-Recall,-F1-Score-of-Hallucination-Detection">4.2 Precision, Recall, F1-Score of Hallucination Detection</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#5.-Scorer-Definitions">5. Scorer Definitions</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#Black-Box-Scorers">Black-Box Scorers</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Exact-Match-Rate-(exact_match)">Exact Match Rate (<code class="docutils literal notranslate"><span class="pre">exact_match</span></code>)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Non-Contradiction-Probability-(noncontradiction)">Non-Contradiction Probability (<code class="docutils literal notranslate"><span class="pre">noncontradiction</span></code>)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Normalized-Semantic-Negentropy-(semantic_negentropy)">Normalized Semantic Negentropy (<code class="docutils literal notranslate"><span class="pre">semantic_negentropy</span></code>)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#BERTScore-(bert_score)">BERTScore (<code class="docutils literal notranslate"><span class="pre">bert_score</span></code>)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#BLEURT-(bleurt)">BLEURT (<code class="docutils literal notranslate"><span class="pre">bleurt</span></code>)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Normalized-Cosine-Similarity-(cosine_sim)">Normalized Cosine Similarity (<code class="docutils literal notranslate"><span class="pre">cosine_sim</span></code>)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Length-Normalized-Token-Probability-(normalized_probability)">Length-Normalized Token Probability (<code class="docutils literal notranslate"><span class="pre">normalized_probability</span></code>)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Minimum-Token-Probability-(min_probability)">Minimum Token Probability (<code class="docutils literal notranslate"><span class="pre">min_probability</span></code>)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Continuous-Judge-Template-(continuous)">Continuous Judge Template (<code class="docutils literal notranslate"><span class="pre">continuous</span></code>)</a></li>
</ul>
  </nav></div>

  <div class="sidebar-secondary-item">
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="../../_sources/_notebooks/examples/ensemble_tuning_demo.ipynb.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
      © Copyright 2025, CVS Health.
      <br/>
    
  </p>
</div>
      
        <div class="footer-item">

  <p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 7.4.7.
    <br/>
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="theme-version">
  <!-- # L10n: Setting the PST URL as an argument as this does not need to be localized -->
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.16.1.
</p></div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>