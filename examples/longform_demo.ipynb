{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0678f84c-2fe2-42be-a69b-21f6b4260245",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Load LLM and device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bd9f1d2-8ff2-4572-bee7-a1cf9db7274d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_google_vertexai import ChatVertexAI\n",
    "\n",
    "llm = ChatVertexAI(model=\"gemini-2.5-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b33e73b-04c3-40f1-afb6-0446aa1fbb49",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Set the torch device\n",
    "if torch.cuda.is_available():  # NVIDIA GPU\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():  # macOS\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")  # CPU\n",
    "print(f\"Using {device.type} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850b7add-c6d7-47e3-985e-02380b1de835",
   "metadata": {},
   "source": [
    "#### LongForm UQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b69f0a78-5501-40db-979e-bbca20f78628",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from uqlm import LongFormUQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a38c40c-7b4d-4a1c-adda-c3b616542a1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompts = [\"write a paragraph about Paul McCartney\", \"write a paragraph about John Lennon\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcd049f3-bb77-4f85-b673-bb0366e9d9ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41b1e2de30c7467b952392cd03841b0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4d685e7bbec4e27b74c8061f6038a67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>response</th>\n",
       "      <th>sampled_responses</th>\n",
       "      <th>prompt</th>\n",
       "      <th>sentence_set</th>\n",
       "      <th>entailment</th>\n",
       "      <th>noncontradiction</th>\n",
       "      <th>contrasted_entailment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sir Paul McCartney stands as one of the most i...</td>\n",
       "      <td>[Paul McCartney stands as one of the most icon...</td>\n",
       "      <td>write a paragraph about Paul McCartney</td>\n",
       "      <td>[Sir Paul McCartney stands as one of the most ...</td>\n",
       "      <td>0.462897</td>\n",
       "      <td>0.998953</td>\n",
       "      <td>0.992700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>John Lennon remains one of the most iconic and...</td>\n",
       "      <td>[John Lennon remains an indelible figure in mu...</td>\n",
       "      <td>write a paragraph about John Lennon</td>\n",
       "      <td>[John Lennon remains one of the most iconic an...</td>\n",
       "      <td>0.526690</td>\n",
       "      <td>0.997217</td>\n",
       "      <td>0.989133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            response  \\\n",
       "0  Sir Paul McCartney stands as one of the most i...   \n",
       "1  John Lennon remains one of the most iconic and...   \n",
       "\n",
       "                                   sampled_responses  \\\n",
       "0  [Paul McCartney stands as one of the most icon...   \n",
       "1  [John Lennon remains an indelible figure in mu...   \n",
       "\n",
       "                                   prompt  \\\n",
       "0  write a paragraph about Paul McCartney   \n",
       "1     write a paragraph about John Lennon   \n",
       "\n",
       "                                        sentence_set  entailment  \\\n",
       "0  [Sir Paul McCartney stands as one of the most ...    0.462897   \n",
       "1  [John Lennon remains one of the most iconic an...    0.526690   \n",
       "\n",
       "   noncontradiction  contrasted_entailment  \n",
       "0          0.998953               0.992700  \n",
       "1          0.997217               0.989133  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sentence-Response UQ: aggregated response-level scoring\n",
    "sent_lfuq = LongFormUQ(llm=llm, granularity=\"sentence\", mode=\"unit_response\", aggregation_method=\"mean\", device=device)\n",
    "result = await sent_lfuq.generate_and_score(prompts=prompts, num_responses=2)\n",
    "result.to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84d5c58f-b32c-44cb-aba9-9e3e466e2629",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c04eeebad2634996a102c243aed92941",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9aeb6b79bb448a59984248e2c26ac70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>response</th>\n",
       "      <th>sampled_responses</th>\n",
       "      <th>prompt</th>\n",
       "      <th>sentence_set</th>\n",
       "      <th>entailment</th>\n",
       "      <th>noncontradiction</th>\n",
       "      <th>contrasted_entailment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sir Paul McCartney stands as one of the most i...</td>\n",
       "      <td>[Sir Paul McCartney stands as one of the most ...</td>\n",
       "      <td>write a paragraph about Paul McCartney</td>\n",
       "      <td>[Sir Paul McCartney stands as one of the most ...</td>\n",
       "      <td>[0.9603798389434814, 0.35361579060554504, 0.83...</td>\n",
       "      <td>[0.9993108212947845, 0.9985859990119934, 0.999...</td>\n",
       "      <td>[0.9992883503437042, 0.9945769309997559, 0.999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>John Lennon remains one of the most iconic and...</td>\n",
       "      <td>[John Lennon was a pivotal figure in 20th-cent...</td>\n",
       "      <td>write a paragraph about John Lennon</td>\n",
       "      <td>[John Lennon remains one of the most iconic an...</td>\n",
       "      <td>[0.3790244683623314, 0.32654259726405144]</td>\n",
       "      <td>[0.9929681718349457, 0.998896449804306]</td>\n",
       "      <td>[0.9831673800945282, 0.9907431304454803]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            response  \\\n",
       "0  Sir Paul McCartney stands as one of the most i...   \n",
       "1  John Lennon remains one of the most iconic and...   \n",
       "\n",
       "                                   sampled_responses  \\\n",
       "0  [Sir Paul McCartney stands as one of the most ...   \n",
       "1  [John Lennon was a pivotal figure in 20th-cent...   \n",
       "\n",
       "                                   prompt  \\\n",
       "0  write a paragraph about Paul McCartney   \n",
       "1     write a paragraph about John Lennon   \n",
       "\n",
       "                                        sentence_set  \\\n",
       "0  [Sir Paul McCartney stands as one of the most ...   \n",
       "1  [John Lennon remains one of the most iconic an...   \n",
       "\n",
       "                                          entailment  \\\n",
       "0  [0.9603798389434814, 0.35361579060554504, 0.83...   \n",
       "1          [0.3790244683623314, 0.32654259726405144]   \n",
       "\n",
       "                                    noncontradiction  \\\n",
       "0  [0.9993108212947845, 0.9985859990119934, 0.999...   \n",
       "1            [0.9929681718349457, 0.998896449804306]   \n",
       "\n",
       "                               contrasted_entailment  \n",
       "0  [0.9992883503437042, 0.9945769309997559, 0.999...  \n",
       "1           [0.9831673800945282, 0.9907431304454803]  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sentence-Response UQ: sentence-level scoring\n",
    "sent_lfuq = LongFormUQ(llm=llm, granularity=\"sentence\", mode=\"unit_response\", aggregation_method=None, device=device)\n",
    "result = await sent_lfuq.generate_and_score(prompts=prompts, num_responses=2)\n",
    "result.to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "195ee8a7-b417-42d9-b5e4-23769ba1f6f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6549604c157e47718d8c0f057bae651e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64978cea294e45b38250d9ef5dc06f20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>response</th>\n",
       "      <th>sampled_responses</th>\n",
       "      <th>prompt</th>\n",
       "      <th>claim_set</th>\n",
       "      <th>entailment</th>\n",
       "      <th>noncontradiction</th>\n",
       "      <th>contrasted_entailment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sir Paul McCartney stands as an undeniable tit...</td>\n",
       "      <td>[Sir Paul McCartney stands as one of the most ...</td>\n",
       "      <td>write a paragraph about Paul McCartney</td>\n",
       "      <td>[Sir Paul McCartney stands as a titan of music...</td>\n",
       "      <td>[0.9855940639972687, 0.9688562452793121, 0.112...</td>\n",
       "      <td>[0.9996415674686432, 0.9994828701019287, 0.974...</td>\n",
       "      <td>[0.9996362328529358, 0.9994658827781677, 0.723...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>John Lennon, an indelible figure in 20th-centu...</td>\n",
       "      <td>[John Lennon remains one of the most iconic an...</td>\n",
       "      <td>write a paragraph about John Lennon</td>\n",
       "      <td>[John Lennon was an indelible figure., John Le...</td>\n",
       "      <td>[0.9055130183696747, 0.927878350019455, 0.9042...</td>\n",
       "      <td>[0.9991505146026611, 0.9993012547492981, 0.999...</td>\n",
       "      <td>[0.999048501253128, 0.9992361068725586, 0.9990...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            response  \\\n",
       "0  Sir Paul McCartney stands as an undeniable tit...   \n",
       "1  John Lennon, an indelible figure in 20th-centu...   \n",
       "\n",
       "                                   sampled_responses  \\\n",
       "0  [Sir Paul McCartney stands as one of the most ...   \n",
       "1  [John Lennon remains one of the most iconic an...   \n",
       "\n",
       "                                   prompt  \\\n",
       "0  write a paragraph about Paul McCartney   \n",
       "1     write a paragraph about John Lennon   \n",
       "\n",
       "                                           claim_set  \\\n",
       "0  [Sir Paul McCartney stands as a titan of music...   \n",
       "1  [John Lennon was an indelible figure., John Le...   \n",
       "\n",
       "                                          entailment  \\\n",
       "0  [0.9855940639972687, 0.9688562452793121, 0.112...   \n",
       "1  [0.9055130183696747, 0.927878350019455, 0.9042...   \n",
       "\n",
       "                                    noncontradiction  \\\n",
       "0  [0.9996415674686432, 0.9994828701019287, 0.974...   \n",
       "1  [0.9991505146026611, 0.9993012547492981, 0.999...   \n",
       "\n",
       "                               contrasted_entailment  \n",
       "0  [0.9996362328529358, 0.9994658827781677, 0.723...  \n",
       "1  [0.999048501253128, 0.9992361068725586, 0.9990...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Claim-Response UQ:  claim-level scoring\n",
    "claim_lfuq = LongFormUQ(llm=llm, granularity=\"claim\", mode=\"unit_response\", aggregation_method=None, device=device)\n",
    "result = await claim_lfuq.generate_and_score(prompts=prompts, num_responses=2)\n",
    "result.to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3db1976-5a48-4bc4-8982-d9712faea044",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cfa2ed5c9234cf298769b079ef12f4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6533961a286a400dafbbd22edfecbd73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>response</th>\n",
       "      <th>sampled_responses</th>\n",
       "      <th>prompt</th>\n",
       "      <th>sentence_set</th>\n",
       "      <th>entailment</th>\n",
       "      <th>noncontradiction</th>\n",
       "      <th>contrasted_entailment</th>\n",
       "      <th>cosine_sim</th>\n",
       "      <th>bert_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sir Paul McCartney is one of the most iconic a...</td>\n",
       "      <td>[Sir Paul McCartney stands as one of the most ...</td>\n",
       "      <td>write a paragraph about Paul McCartney</td>\n",
       "      <td>[Sir Paul McCartney is one of the most iconic ...</td>\n",
       "      <td>[0.4279695302248001, 0.2414419180713594, 0.058...</td>\n",
       "      <td>[0.9994330704212189, 0.9995861351490021, 0.999...</td>\n",
       "      <td>[0.9957833886146545, 0.976411372423172, 0.9844...</td>\n",
       "      <td>[0.9231644421815872, 0.8462588638067245, 0.911...</td>\n",
       "      <td>[0.930171549320221, 0.8999151587486267, 0.8983...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>John Lennon remains one of the most iconic and...</td>\n",
       "      <td>[John Lennon remains one of the most iconic an...</td>\n",
       "      <td>write a paragraph about John Lennon</td>\n",
       "      <td>[John Lennon remains one of the most iconic an...</td>\n",
       "      <td>[0.4112534672021866, 0.20153965055942535, 0.38...</td>\n",
       "      <td>[0.9993768334388733, 0.999542236328125, 0.9992...</td>\n",
       "      <td>[0.9962629675865173, 0.9955682456493378, 0.993...</td>\n",
       "      <td>[0.9497462511062622, 0.8846983760595322, 0.887...</td>\n",
       "      <td>[0.9456483721733093, 0.923531711101532, 0.8986...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            response  \\\n",
       "0  Sir Paul McCartney is one of the most iconic a...   \n",
       "1  John Lennon remains one of the most iconic and...   \n",
       "\n",
       "                                   sampled_responses  \\\n",
       "0  [Sir Paul McCartney stands as one of the most ...   \n",
       "1  [John Lennon remains one of the most iconic an...   \n",
       "\n",
       "                                   prompt  \\\n",
       "0  write a paragraph about Paul McCartney   \n",
       "1     write a paragraph about John Lennon   \n",
       "\n",
       "                                        sentence_set  \\\n",
       "0  [Sir Paul McCartney is one of the most iconic ...   \n",
       "1  [John Lennon remains one of the most iconic an...   \n",
       "\n",
       "                                          entailment  \\\n",
       "0  [0.4279695302248001, 0.2414419180713594, 0.058...   \n",
       "1  [0.4112534672021866, 0.20153965055942535, 0.38...   \n",
       "\n",
       "                                    noncontradiction  \\\n",
       "0  [0.9994330704212189, 0.9995861351490021, 0.999...   \n",
       "1  [0.9993768334388733, 0.999542236328125, 0.9992...   \n",
       "\n",
       "                               contrasted_entailment  \\\n",
       "0  [0.9957833886146545, 0.976411372423172, 0.9844...   \n",
       "1  [0.9962629675865173, 0.9955682456493378, 0.993...   \n",
       "\n",
       "                                          cosine_sim  \\\n",
       "0  [0.9231644421815872, 0.8462588638067245, 0.911...   \n",
       "1  [0.9497462511062622, 0.8846983760595322, 0.887...   \n",
       "\n",
       "                                          bert_score  \n",
       "0  [0.930171549320221, 0.8999151587486267, 0.8983...  \n",
       "1  [0.9456483721733093, 0.923531711101532, 0.8986...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# matched sentence UQ: sentence-level scoring\n",
    "matched_sent_lfuq = LongFormUQ(llm=llm, granularity=\"sentence\", mode=\"matched_unit\", aggregation_method=None, device=device)\n",
    "result = await matched_sent_lfuq.generate_and_score(prompts=prompts, num_responses=2)\n",
    "result.to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e50a2e1-0f63-4479-b66f-76f463b05f06",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18c2f020fdad48c6bf588ecbc41b2348",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97326ed6cce34a359c4deef74ef99f02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>response</th>\n",
       "      <th>sampled_responses</th>\n",
       "      <th>prompt</th>\n",
       "      <th>claim_set</th>\n",
       "      <th>entailment</th>\n",
       "      <th>noncontradiction</th>\n",
       "      <th>contrasted_entailment</th>\n",
       "      <th>cosine_sim</th>\n",
       "      <th>bert_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sir Paul McCartney stands as one of the most i...</td>\n",
       "      <td>[Paul McCartney, a towering figure in popular ...</td>\n",
       "      <td>write a paragraph about Paul McCartney</td>\n",
       "      <td>[Sir Paul McCartney stands as a figure., Sir P...</td>\n",
       "      <td>[0.8556037843227386, 0.509904257953167, 0.5171...</td>\n",
       "      <td>[0.9990790486335754, 0.999342292547226, 0.9994...</td>\n",
       "      <td>[0.9988324046134949, 0.9955945611000061, 0.992...</td>\n",
       "      <td>[0.8817749470472336, 0.9349848031997681, 0.960...</td>\n",
       "      <td>[0.9203675985336304, 0.9631945490837097, 0.966...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>John Lennon, an iconic English singer, songwri...</td>\n",
       "      <td>[John Lennon remains one of the most iconic an...</td>\n",
       "      <td>write a paragraph about John Lennon</td>\n",
       "      <td>[John Lennon was an iconic English singer., Jo...</td>\n",
       "      <td>[0.2559227691963315, 0.2893851175904274, 0.309...</td>\n",
       "      <td>[0.9991565048694611, 0.9993019998073578, 0.999...</td>\n",
       "      <td>[0.9504534900188446, 0.9786828458309174, 0.988...</td>\n",
       "      <td>[0.9312989860773087, 0.9325282126665115, 0.934...</td>\n",
       "      <td>[0.9544923901557922, 0.9515130519866943, 0.955...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            response  \\\n",
       "0  Sir Paul McCartney stands as one of the most i...   \n",
       "1  John Lennon, an iconic English singer, songwri...   \n",
       "\n",
       "                                   sampled_responses  \\\n",
       "0  [Paul McCartney, a towering figure in popular ...   \n",
       "1  [John Lennon remains one of the most iconic an...   \n",
       "\n",
       "                                   prompt  \\\n",
       "0  write a paragraph about Paul McCartney   \n",
       "1     write a paragraph about John Lennon   \n",
       "\n",
       "                                           claim_set  \\\n",
       "0  [Sir Paul McCartney stands as a figure., Sir P...   \n",
       "1  [John Lennon was an iconic English singer., Jo...   \n",
       "\n",
       "                                          entailment  \\\n",
       "0  [0.8556037843227386, 0.509904257953167, 0.5171...   \n",
       "1  [0.2559227691963315, 0.2893851175904274, 0.309...   \n",
       "\n",
       "                                    noncontradiction  \\\n",
       "0  [0.9990790486335754, 0.999342292547226, 0.9994...   \n",
       "1  [0.9991565048694611, 0.9993019998073578, 0.999...   \n",
       "\n",
       "                               contrasted_entailment  \\\n",
       "0  [0.9988324046134949, 0.9955945611000061, 0.992...   \n",
       "1  [0.9504534900188446, 0.9786828458309174, 0.988...   \n",
       "\n",
       "                                          cosine_sim  \\\n",
       "0  [0.8817749470472336, 0.9349848031997681, 0.960...   \n",
       "1  [0.9312989860773087, 0.9325282126665115, 0.934...   \n",
       "\n",
       "                                          bert_score  \n",
       "0  [0.9203675985336304, 0.9631945490837097, 0.966...  \n",
       "1  [0.9544923901557922, 0.9515130519866943, 0.955...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# matched claim UQ: claim-level scoring\n",
    "matched_claim_lfuq = LongFormUQ(llm=llm, granularity=\"claim\", mode=\"matched_unit\", aggregation_method=None, device=device)\n",
    "result = await matched_claim_lfuq.generate_and_score(prompts=prompts, num_responses=2)\n",
    "result.to_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671d0d56-4dfc-4607-8222-46828b90e427",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16a38c6b-6ae5-4fe8-addc-68f639d3ffb2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from uqlm.longform import ResponseDecomposer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06cf93d8-320e-4fd8-a2d8-551f5a3d710f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rd = ResponseDecomposer(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a5fb9e10-96c7-41a9-ab25-a43580ffe47a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "responses = [\"Hello there! Today I visited Dr. Chauhan at his home. He was hanging his framed B.S., M.S., and Ph.D. degrees. It was fun!\", \"One time I went on a class trip to D.C. to visit the white house. While there, I felt in awe of the beutiful art and important people with titles such as Prof., Esq., and others.\"]\n",
    "\n",
    "sampled_responses = [\n",
    "    [\"Hi! I went to see Dr. Chauhan at his house today. He was busy putting up his framed B.S., M.S., and Ph.D. diplomas. It was quite enjoyable!\", \"Greetings! Today, I stopped by Dr. Chauhan's home. He was in the process of displaying his framed degrees: B.S., M.S., and Ph.D. It was a delightful experience!\"],\n",
    "    [\n",
    "        \"Once, I took a school trip to Washington, D.C. to see the White House. While I was there, I was amazed by the stunning artwork and the notable individuals with titles like Professor, Esquire, and more.\",\n",
    "        \"During a class excursion to Washington, D.C., I had the opportunity to visit the White House. I was struck by the beautiful art and the distinguished people holding titles such as Prof., Esq., and others.\",\n",
    "    ],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dfa19681-7702-43ca-9501-b40fc7abf013",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Hello there!',\n",
       "  'Today I visited Dr. Chauhan at his home.',\n",
       "  'He was hanging his framed B.S., M.S., and Ph.D. degrees.',\n",
       "  'It was fun!'],\n",
       " ['One time I went on a class trip to D.C. to visit the white house.',\n",
       "  'While there, I felt in awe of the beutiful art and important people with titles such as Prof., Esq., and others.']]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decompose responses into sentences\n",
    "sentence_sets = rd.decompose_sentences(responses=responses)\n",
    "sentence_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "04da8ce0-ae05-4874-81b6-fedf114c0aee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['Hi!',\n",
       "   'I went to see Dr. Chauhan at his house today.',\n",
       "   'He was busy putting up his framed B.S., M.S., and Ph.D. diplomas.',\n",
       "   'It was quite enjoyable!'],\n",
       "  ['Greetings!',\n",
       "   \"Today, I stopped by Dr. Chauhan's home.\",\n",
       "   'He was in the process of displaying his framed degrees: B.S., M.S., and Ph.D. It was a delightful experience!']],\n",
       " [['Once, I took a school trip to Washington, D.C. to see the White House.',\n",
       "   'While I was there, I was amazed by the stunning artwork and the notable individuals with titles like Professor, Esquire, and more.'],\n",
       "  ['During a class excursion to Washington, D.C., I had the opportunity to visit the White House.',\n",
       "   'I was struck by the beautiful art and the distinguished people holding titles such as Prof., Esq., and others.']]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decompose sampled responses into sentences\n",
    "sampled_sentence_sets = rd.decompose_candidate_sentences(sampled_responses=sampled_responses)\n",
    "sampled_sentence_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f4080394-2088-4d28-9cc2-3ae8484a47ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[],\n",
       " ['The speaker went on a trip.',\n",
       "  'The trip was a class trip.',\n",
       "  'The speaker went to D.C.',\n",
       "  'The speaker visited the white house.',\n",
       "  'The speaker was in D.C.',\n",
       "  'The speaker felt in awe.',\n",
       "  'The speaker felt in awe of the art.',\n",
       "  'The art was beautiful.',\n",
       "  'The speaker felt in awe of the people.',\n",
       "  'The people were important.',\n",
       "  'The people had titles.',\n",
       "  'Prof. was a title.',\n",
       "  'Esq. was a title.',\n",
       "  'Other titles were present.']]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decompose responses into claims\n",
    "claim_sets = await rd.decompose_claims(responses=responses)\n",
    "claim_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cade8967-64e4-4cc4-91d6-d4317df93828",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[], []],\n",
       " [['I took a school trip.',\n",
       "   'The school trip went to Washington, D.C.',\n",
       "   'I went to Washington, D.C. to see the White House.',\n",
       "   'I was in Washington, D.C.',\n",
       "   'I was amazed in Washington, D.C.',\n",
       "   'Stunning artwork caused my amazement.',\n",
       "   'Notable individuals caused my amazement.',\n",
       "   'The notable individuals had titles.',\n",
       "   'Professor was a title of notable individuals.',\n",
       "   'Esquire was a title of notable individuals.',\n",
       "   'Some notable individuals had more titles.'],\n",
       "  ['A class excursion took place.',\n",
       "   'The class excursion was to Washington, D.C.',\n",
       "   'The narrator had an opportunity.',\n",
       "   'The opportunity was during the class excursion.',\n",
       "   'The opportunity was to visit the White House.',\n",
       "   'The narrator was struck by art.',\n",
       "   'The art was beautiful.',\n",
       "   'The narrator was struck by people.',\n",
       "   'The people were distinguished.',\n",
       "   'The people held titles.',\n",
       "   'Prof. was a title.',\n",
       "   'Esq. was a title.',\n",
       "   'The people held other titles.']]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decompose sampled responses into claims\n",
    "sampled_claim_sets = await rd.decompose_candidate_claims(sampled_responses=sampled_responses)\n",
    "sampled_claim_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b7d5c4-e672-4cb0-b7fd-d671b79ca98c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "262d4d0a-584b-4144-8ef2-f14927d5cca8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from uqlm.longform.black_box import UnitResponseScorer, MatchedUnitScorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0b73cc69-1c7e-4b7c-bc3a-0012797c6147",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'entailment': [[[0.9227377772331238, 0.9302507638931274],\n",
       "   [0.9965391159057617, 0.9963691830635071],\n",
       "   [0.989100992679596, 0.9731588363647461],\n",
       "   [0.9052041172981262, 0.7679730653762817]],\n",
       "  [[0.9978324174880981, 0.997478723526001],\n",
       "   [0.9964278340339661, 0.968819260597229]]],\n",
       " 'noncontradiction': [[[0.9921353459358215, 0.9936415553092957],\n",
       "   [0.9997926950454712, 0.9997541904449463],\n",
       "   [0.9995163083076477, 0.9992474913597107],\n",
       "   [0.9986988306045532, 0.9979174137115479]],\n",
       "  [[0.99982750415802, 0.999841034412384],\n",
       "   [0.999812126159668, 0.999585747718811]]],\n",
       " 'contrasted_entailment': [[[0.9915488362312317, 0.9932112097740173],\n",
       "   [0.9997920393943787, 0.9997533559799194],\n",
       "   [0.9995112419128418, 0.9992273449897766],\n",
       "   [0.9985646605491638, 0.9972955584526062]],\n",
       "  [[0.9998271465301514, 0.9998406767845154],\n",
       "   [0.9998114705085754, 0.9995725750923157]]]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urs = UnitResponseScorer()\n",
    "\n",
    "urs_result = urs.evaluate(claim_sets=sentence_sets, sampled_responses=sampled_responses)\n",
    "urs_result.to_dict(return_all=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "277af91c-0c3c-46e6-87e6-29a3ce8099eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'entailment': [[[0.9210313558578491, 0.9471302032470703],\n",
       "   [0.99812251329422, 0.9957913160324097],\n",
       "   [0.9956673979759216, 0.9840846061706543],\n",
       "   [0.9889243841171265, 0.8758251070976257]],\n",
       "  [[0.9977548122406006, 0.996763288974762],\n",
       "   [0.9969518780708313, 0.907191276550293]]],\n",
       " 'noncontradiction': [[[0.9994022250175476, 0.9995139837265015],\n",
       "   [0.9998176693916321, 0.9998164772987366],\n",
       "   [0.9996823072433472, 0.9994068145751953],\n",
       "   [0.9997873306274414, 0.9986640214920044]],\n",
       "  [[0.9998548030853271, 0.9998593926429749],\n",
       "   [0.9998741745948792, 0.9996825456619263]]],\n",
       " 'contrasted_entailment': [[[0.9993513822555542, 0.9994871020317078],\n",
       "   [0.9998173713684082, 0.9998157620429993],\n",
       "   [0.9996810555458069, 0.9993975758552551],\n",
       "   [0.9997850060462952, 0.9983170628547668]],\n",
       "  [[0.9998545050621033, 0.9998589754104614],\n",
       "   [0.9998738169670105, 0.9996501803398132]]],\n",
       " 'cosine_sim': [[[0.8490213751792908, 0.8225279450416565],\n",
       "   [0.9674820899963379, 0.9155158400535583],\n",
       "   [0.899648904800415, 0.8994369208812714],\n",
       "   [0.8989452719688416, 0.6456610858440399]],\n",
       "  [[0.9422740936279297, 0.9277239143848419],\n",
       "   [0.9153868556022644, 0.9420949518680573]]],\n",
       " 'bert_score': [[[0.9163234829902649, 0.8905890583992004],\n",
       "   [0.9575291872024536, 0.9655391573905945],\n",
       "   [0.9744039177894592, 0.9517780542373657],\n",
       "   [0.955289363861084, 0.873611330986023]],\n",
       "  [[0.9631237387657166, 0.9451398253440857],\n",
       "   [0.9155347943305969, 0.9380288124084473]]]}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mus = MatchedUnitScorer()\n",
    "\n",
    "mus_result = mus.evaluate(claim_sets=sentence_sets, sampled_claim_sets=sampled_sentence_sets)\n",
    "mus_result.to_dict(return_all=True)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "uqlm_my_test",
   "name": "workbench-notebooks.m126",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m126"
  },
  "kernelspec": {
   "display_name": "uqlm_my_test",
   "language": "python",
   "name": "uqlm_my_test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
